{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KIVLBz840Bi"
      },
      "source": [
        "# Chain-of-Verification GPT4 Template\n",
        "Chain-of-Verification (CoVe) is a prompt engineering technique to bypass hallucinations. An LLM generates a baseline response to a user query, but this might contain errors. CoVe helps by creating a plan comprising of verification questions that are used to validate the information. This process results in more accurate answers than the initial response. The final answer is revised based on these validations. **[ Link to Paper](https://arxiv.org/pdf/2309.11495.pdf)**\n",
        "\n",
        "**How to use template?**\n",
        "1. Download `cove_template_config.json` (add github link)\n",
        "2. Follow instructions in this notebook.\n",
        "\n",
        "*Need a playground to test your prompts?*\n",
        "Go to this [AI Workbook](https://lastmileai.dev/workbooks/clpa6nv2x00fdqp38oefmz29c) to experiment with your prompts/model params."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install AIConfig package\n",
        "!pip install python-aiconfig"
      ],
      "metadata": {
        "id": "k3tsITZhVFp-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "51w-3OZC_Z97"
      },
      "outputs": [],
      "source": [
        "# Import required modules from AIConfig and other dependencies\n",
        "import openai\n",
        "import pandas as pd\n",
        "from google.colab import userdata\n",
        "from aiconfig import AIConfigRuntime, CallbackManager, InferenceOptions\n",
        "\n",
        "# Use your OpenAI Key\n",
        "openai.api_key = userdata.get('openai_key')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "6cAw1ekXCxGn"
      },
      "outputs": [],
      "source": [
        "# First, upload `cove_template_config.json`to Files in Colab Notebook\n",
        "# Load the config.\n",
        "config = AIConfigRuntime.load(\"cove_template_config.json\")\n",
        "config.callback_manager = CallbackManager([])\n",
        "\n",
        "# Setup for streaming responses from LLM\n",
        "inference_options = InferenceOptions()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykZE2ieO6ryn"
      },
      "source": [
        "## 1. Baseline Response\n",
        "Prompt LLM with user question. The baseline response from the LLM might contain inaccuracies that we will want to verify. The user prompt is from AIConfig named\n",
        "`baseline_response_gen`.\n",
        "\n",
        "**Prompt: Name 15 politicians who were born in New York City, New York.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbolW2mVDeZD",
        "outputId": "1a066669-65b3-49ea-b234-91a25cc1a5fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Theodore Roosevelt - 26th President of the United States\n",
            "2. Franklin D. Roosevelt - 32nd President of the United States\n",
            "3. Donald Trump - 45th President of the United States\n",
            "4. Michael Bloomberg - Former Mayor of New York City\n",
            "5. Rudy Giuliani - Former Mayor of New York City\n",
            "6. Alexander Hamilton - Founding Father of the United States\n",
            "7. Eliot Spitzer - Former Governor of New York\n",
            "8. Chuck Schumer - U.S. Senator from New York\n",
            "9. Kirsten Gillibrand - U.S. Senator from New York\n",
            "10. Bill de Blasio - Former Mayor of New York City\n",
            "11. Andrew Cuomo - Former Governor of New York\n",
            "12. Eric Schneiderman - Former Attorney General of New York\n",
            "13. Letitia James - Attorney General of New York\n",
            "14. Alexandria Ocasio-Cortez - U.S. Representative from New York\n",
            "15. Adam Clayton Powell Jr. - Former U.S. Representative from New York"
          ]
        }
      ],
      "source": [
        "# TODO: Update baseline_prompt but ensure it is structured in a way that outputs a list of entities where each can be verified.\n",
        "baseline_prompt = \"Name 15 politicians who were born in New York City, New York\"\n",
        "\n",
        "async def run_baseline_prompt(baseline_prompt):\n",
        "    \"\"\"\n",
        "    Run GPT4 baseline prompt to generate a list of entities and retrieve the response.\n",
        "\n",
        "    :param baseline_prompt: User query for baseline prompt (runs with GPT4)\n",
        "    :return: The output text from the generated baseline response.\n",
        "    \"\"\"\n",
        "    params = {\"baseline_prompt\": baseline_prompt}\n",
        "\n",
        "    await config.run(\"baseline_response_gen\", params, inference_options)\n",
        "    return config.get_output_text(\"baseline_response_gen\")\n",
        "\n",
        "baseline_reponse = await run_baseline_prompt(baseline_prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7OQNz9cM7Myv"
      },
      "source": [
        "\n",
        "## 2. Setup and Test Verification Question\n",
        "Given both query and baseline response, generate a verification\n",
        "question that could help to self-analyze if there are any mistakes in the original response. We will use one verification question here. The verification prompt is from AIConfig, named `verification`.\n",
        "\n",
        "**Verification Prompt: Where was {{entity}} born?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jD9S3q5mMtqd",
        "outputId": "f90ac37d-cf19-4318-b0b3-542eae515228"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Franklin D. Roosevelt was born in Hyde Park, New York, USA."
          ]
        }
      ],
      "source": [
        "# TODO: Update verification question that takes in entity as a parameter\n",
        "verification_question = \"Where was {{entity}} born\"\n",
        "\n",
        "async def run_single_verification(verification_question, entity):\n",
        "    \"\"\"\n",
        "    Runs GPT4 single verification prompt and returns the response.\n",
        "\n",
        "    :param verification_question: The question to verify each entity from the baseline response.\n",
        "    :param entity: The single entity to be verified.\n",
        "    :return: Response from the LLM.\n",
        "    \"\"\"\n",
        "    params = {\n",
        "        \"verification_question\": verification_question,\n",
        "        \"entity\": entity\n",
        "    }\n",
        "\n",
        "    # Disables irrelevant chat context to avoid context limits\n",
        "    config.set_metadata(\"remember_chat_context\", False, \"verification\")\n",
        "\n",
        "    verification_completion = await config.run(\"verification\", params, options=inference_options)\n",
        "\n",
        "    return verification_completion\n",
        "\n",
        "# Test verification question on a single entity\n",
        "verification_completion = await run_single_verification(verification_question, \"Franklin D. Roosevelt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9Zaypp075f9"
      },
      "source": [
        "## 3. Execute Verifications\n",
        "Answer each verification question for each entity from the the baseline response. Save the verification results to be used to generate the revised response."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "QFew6GhONR8X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b6834ba-fc6c-44f6-923a-164f005b3375"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Theodore Roosevelt was born in New York City, New York, USA.\n",
            "\n",
            "Franklin D. Roosevelt was born in Hyde Park, New York, USA.\n",
            "\n",
            "Donald Trump was born in Queens, New York, USA.\n",
            "\n",
            "Michael Bloomberg was born in Boston, Massachusetts, USA.\n",
            "\n",
            "Rudy Giuliani was born in Brooklyn, New York, USA.\n",
            "\n",
            "Chuck Schumer was born in Brooklyn, New York, USA.\n",
            "\n",
            "Kirsten Gillibrand was born in Albany, New York, USA.\n",
            "\n",
            "Alexandria Ocasio-Cortez was born in The Bronx, New York City, USA.\n",
            "\n",
            "Eliot Spitzer was born in The Bronx, New York, USA.\n",
            "\n",
            "Andrew Cuomo was born in Queens, New York, USA.\n",
            "\n",
            "Bill de Blasio was born in Manhattan, New York, USA.\n",
            "\n",
            "Eric Adams was born in Brownsville, Brooklyn, New York City, USA.\n",
            "\n",
            "Jerrold Nadler was born in Brooklyn, New York, USA.\n",
            "\n",
            "Carolyn Maloney was born in Greensboro, North Carolina, USA.\n",
            "\n",
            "Letitia James was born in Brooklyn, New York, USA.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def gen_entities_list(baseline_response):\n",
        "  \"\"\"\n",
        "  Extracts entity names from a given baseline response by processing each line with regex.\n",
        "  TODO: Update regex if the format of the baseline response changes. (ex. not a numbered list)\n",
        "\n",
        "  :param baseline_response: A string of newline-separated entity records.\n",
        "  :return: A list of extracted entity names.\n",
        "  \"\"\"\n",
        "  rows = baseline_response.split('\\n')\n",
        "  entities = []\n",
        "\n",
        "  for row in rows:\n",
        "      if not row.strip():\n",
        "          continue\n",
        "      entities.append(pd.Series(row).str.extract(r'(\\d+\\.\\s)([^,]*)')[1].values[0])\n",
        "\n",
        "  return entities\n",
        "\n",
        "async def gen_verification_results(entities):\n",
        "  \"\"\"\n",
        "  Runs GPT4 verification prompt for each entity and concatenates returned verifications into a single string.\n",
        "\n",
        "  :param entities: List of entity names to verify.\n",
        "  :return: String containing all verification results.\n",
        "  \"\"\"\n",
        "  verification_data = \"\"\n",
        "  for n in entities:\n",
        "      params = {\"entity\": n}\n",
        "      verification_completion = await config.run(\"verification\", params, options=inference_options)\n",
        "      single_verification_text = config.get_output_text(\"verification\")\n",
        "      verification_data += \" \" + single_verification_text\n",
        "      print(\"\\n\")\n",
        "\n",
        "  return single_verification_text\n",
        "\n",
        "\n",
        "entities = gen_entities_list(baseline_response)\n",
        "verification_data = await gen_verification_results(entities)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ldof6NdR86qI"
      },
      "source": [
        "## 4. Generate Revised Response\n",
        "Given the discovered inconsistencies (if any), generate a revised response incorporating the verification results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4MiNxiJc9GPI",
        "outputId": "a095309a-e0d2-489a-a4f0-a9e2a23ef646"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### Revised Response \n",
            "1. Theodore Roosevelt - 26th President of the United States\n",
            "2. Franklin D. Roosevelt - 32nd President of the United States\n",
            "3. Donald Trump - 45th President of the United States\n",
            "4. Michael Bloomberg - Former Mayor of New York City\n",
            "5. Rudy Giuliani - Former Mayor of New York City\n",
            "6. Alexander Hamilton - Founding Father of the United States\n",
            "7. Eliot Spitzer - Former Governor of New York\n",
            "8. Chuck Schumer - U.S. Senator from New York\n",
            "9. Kirsten Gillibrand - U.S. Senator from New York\n",
            "10. Bill de Blasio - Former Mayor of New York City\n",
            "11. Andrew Cuomo - Former Governor of New York\n",
            "12. Eric Schneiderman - Former Attorney General of New York\n",
            "13. Alexandria Ocasio-Cortez - U.S. Representative from New York\n",
            "14. Adam Clayton Powell Jr. - Former U.S. Representative from New York\n",
            "\n",
            "### Failed Entities \n",
            "Letitia James - Attorney General of New York. Reason: The verification data shows that Letitia James was born in Brooklyn, New York, not New York City, New York."
          ]
        }
      ],
      "source": [
        "# Disable irrelevant chat context to avoid context limits\n",
        "config.set_metadata(\"remember_chat_context\", False, \"final_response_gen\")\n",
        "\n",
        "# Generated the revised response using verification data\n",
        "params = {\"verification_results\": verification_data}\n",
        "revised_response = await config.run(\"final_response_gen\", params, options=inference_options)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}