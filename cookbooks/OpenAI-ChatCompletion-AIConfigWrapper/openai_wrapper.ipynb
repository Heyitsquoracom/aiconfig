{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Api Key\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "original_create = openai.chat.completions.create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "\n",
    "def pretty_print_file(file_name):\n",
    "    with open(file_name, 'r') as f:\n",
    "        pp = pprint.PrettyPrinter(indent=4, width = 150)\n",
    "        pp.pprint(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/aiconfig/lib/python3.10/site-packages/pydantic/_internal/_fields.py:149: UserWarning: Field \"model_parsers\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/aiconfig/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat Completion Response: \n",
      "ChatCompletion(id='chatcmpl-8PgfXpinkNKYLUUhswWDHm8diAP7c', choices=[Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Hello! How can I assist you today?', role='assistant', function_call=None, tool_calls=None))], created=1701132911, model='gpt-3.5-turbo-0613', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=9, prompt_tokens=8, total_tokens=17))\n",
      "\n",
      "Generated AIConfig Json: \n",
      "('{\\n'\n",
      " '  \"name\": \"\",\\n'\n",
      " '  \"schema_version\": \"latest\",\\n'\n",
      " '  \"metadata\": {\\n'\n",
      " '    \"parameters\": {},\\n'\n",
      " '    \"models\": {}\\n'\n",
      " '  },\\n'\n",
      " '  \"description\": \"\",\\n'\n",
      " '  \"prompts\": [\\n'\n",
      " '    {\\n'\n",
      " '      \"name\": \"prompt_0\",\\n'\n",
      " '      \"input\": \"Hi\",\\n'\n",
      " '      \"metadata\": {\\n'\n",
      " '        \"model\": {\\n'\n",
      " '          \"name\": \"gpt-3.5-turbo\",\\n'\n",
      " '          \"settings\": {\\n'\n",
      " '            \"model\": \"gpt-3.5-turbo\",\\n'\n",
      " '            \"top_p\": 1,\\n'\n",
      " '            \"max_tokens\": 3000,\\n'\n",
      " '            \"temperature\": 1,\\n'\n",
      " '            \"stream\": false\\n'\n",
      " '          }\\n'\n",
      " '        },\\n'\n",
      " '        \"parameters\": {},\\n'\n",
      " '        \"remember_chat_context\": true\\n'\n",
      " '      },\\n'\n",
      " '      \"outputs\": [\\n'\n",
      " '        {\\n'\n",
      " '          \"output_type\": \"execute_result\",\\n'\n",
      " '          \"execution_count\": 0,\\n'\n",
      " '          \"data\": {\\n'\n",
      " '            \"content\": \"Hello! How can I assist you today?\",\\n'\n",
      " '            \"role\": \"assistant\"\\n'\n",
      " '          },\\n'\n",
      " '          \"metadata\": {\\n'\n",
      " '            \"id\": \"chatcmpl-8PgfXpinkNKYLUUhswWDHm8diAP7c\",\\n'\n",
      " '            \"created\": 1701132911,\\n'\n",
      " '            \"model\": \"gpt-3.5-turbo-0613\",\\n'\n",
      " '            \"object\": \"chat.completion\",\\n'\n",
      " '            \"usage\": {\\n'\n",
      " '              \"completion_tokens\": 9,\\n'\n",
      " '              \"prompt_tokens\": 8,\\n'\n",
      " '              \"total_tokens\": 17\\n'\n",
      " '            },\\n'\n",
      " '            \"finish_reason\": \"stop\"\\n'\n",
      " '          }\\n'\n",
      " '        }\\n'\n",
      " '      ]\\n'\n",
      " '    }\\n'\n",
      " '  ]\\n'\n",
      " '}')\n"
     ]
    }
   ],
   "source": [
    "# Set Once and every call will create an AIConfig\n",
    "import openai\n",
    "from aiconfig.ChatCompletion import create_and_save_to_config\n",
    "openai.chat.completions.create = create_and_save_to_config()\n",
    "\n",
    "# Basic Execution\n",
    "completion_params = {\n",
    "            \"model\": \"gpt-3.5-turbo\",\n",
    "            \"top_p\": 1,\n",
    "            \"max_tokens\": 3000,\n",
    "            \"temperature\": 1,\n",
    "            \"stream\": False,\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"content\": \"Hi\",\n",
    "                    \"role\": \"user\",\n",
    "                }\n",
    "            ],\n",
    "        }\n",
    "\n",
    "response = openai.chat.completions.create(**completion_params) # Creates a config saved to default path `aiconfig.json`\n",
    "print(\"Chat Completion Response: \")\n",
    "pprint.pprint(response)\n",
    "\n",
    "print(\"\\nGenerated AIConfig Json: \")\n",
    "pretty_print_file('aiconfig.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat Completion Streaming Response: \n",
      "Once upon a time, in a quaint little village nestled in the heart of a magical forest, lived a young boy named Oliver. Oliver was an adventurous and curious soul, always seeking a new and thrilling experience. One day, while exploring the woods, he stumbled upon an ancient, weathered map tucked inside a hollowed-out tree trunk.\n",
      "\n",
      "Intrigued by the mysterious markings on the map, Oliver decided to embark on a quest to uncover the treasure it promised. With his loyal companion, a mischievous fox named Lily, by his side, they followed the map's directions, leading them deep into the heart of the forest.\n",
      "\n",
      "As they ventured further, the forest became thicker, the air heavy with enchantment. Suddenly, they stumbled upon an immense stone door adorned with intricate carvings and symbols. Eager to unlock the secrets beyond, Oliver examined the map once more, looking for any clues.\n",
      "\n",
      "The map indicated that to gain entry, they needed to collect three enchanted keys hidden throughout the forest. Determined to prevail, Oliver and Lily set off on a series of thrilling and dangerous challenges, navigating through treacherous swamps, scaling towering trees, and braving ferocious beasts that guarded the keys.\n",
      "\n",
      "Their journey was arduous and fraught with peril, but Oliver's unwavering determination and Lily's cleverness proved to be a powerful combination. They collected the first two keys, each unlocking a new path filled with wonders and dangers.\n",
      "\n",
      "Finally, they arrived at the final location, an ancient crumbling castle atop a mountain. The last key awaited them, hidden amidst a labyrinth of dark tunnels and guarded by a fearsome dragon rumored to possess incredible strength.\n",
      "\n",
      "Unfazed by the dragon's daunting presence, Oliver confronted it with bravery and a cunning plan. He distracted the dragon with Lily's playful antics while stealthily retrieving the key. As the dragon slumbered, they carefully made their escape, leaving the castle behind in awe of their feat.\n",
      "\n",
      "With the three keys in their possession, Oliver and Lily raced back to the stone door, their hearts thundering with excitement. As they inserted the keys into the corresponding keyholes, the door rumbled and groaned, magically coming to life, revealing a dazzling treasure room glowing with gold and precious gems.\n",
      "\n",
      "Oliver's eyes widened in awe as he discovered that the true treasure was not the material wealth before him, but the knowledge contained within ancient scrolls and artifacts lining the shelves. With newfound wisdom and tales to share, Oliver and Lily returned to the village as heroes, forever changed by their extraordinary adventures.\n",
      "\n",
      "Word of their triumphs spread far and wide, inspiring adventurers from all corners of the world to delve into the enchanted forest in search of their own destinies. And so, the legend of Oliver and Lily lived on, reminding future generations about the power of courage, friendship, and the wonders hidden within our wildest dreams.\n",
      "Generated AIConfig Json: \n",
      "('{\\n'\n",
      " '  \"name\": \"\",\\n'\n",
      " '  \"schema_version\": \"latest\",\\n'\n",
      " '  \"metadata\": {\\n'\n",
      " '    \"parameters\": {},\\n'\n",
      " '    \"models\": {}\\n'\n",
      " '  },\\n'\n",
      " '  \"description\": \"\",\\n'\n",
      " '  \"prompts\": [\\n'\n",
      " '    {\\n'\n",
      " '      \"name\": \"prompt_0\",\\n'\n",
      " '      \"input\": \"Hi\",\\n'\n",
      " '      \"metadata\": {\\n'\n",
      " '        \"model\": {\\n'\n",
      " '          \"name\": \"gpt-3.5-turbo\",\\n'\n",
      " '          \"settings\": {\\n'\n",
      " '            \"model\": \"gpt-3.5-turbo\",\\n'\n",
      " '            \"top_p\": 1,\\n'\n",
      " '            \"max_tokens\": 3000,\\n'\n",
      " '            \"temperature\": 1,\\n'\n",
      " '            \"stream\": false\\n'\n",
      " '          }\\n'\n",
      " '        },\\n'\n",
      " '        \"parameters\": {},\\n'\n",
      " '        \"remember_chat_context\": true\\n'\n",
      " '      },\\n'\n",
      " '      \"outputs\": [\\n'\n",
      " '        {\\n'\n",
      " '          \"output_type\": \"execute_result\",\\n'\n",
      " '          \"execution_count\": 0,\\n'\n",
      " '          \"data\": {\\n'\n",
      " '            \"content\": \"Hello! How can I assist you today?\",\\n'\n",
      " '            \"role\": \"assistant\"\\n'\n",
      " '          },\\n'\n",
      " '          \"metadata\": {\\n'\n",
      " '            \"id\": \"chatcmpl-8PgfXpinkNKYLUUhswWDHm8diAP7c\",\\n'\n",
      " '            \"created\": 1701132911,\\n'\n",
      " '            \"model\": \"gpt-3.5-turbo-0613\",\\n'\n",
      " '            \"object\": \"chat.completion\",\\n'\n",
      " '            \"usage\": {\\n'\n",
      " '              \"completion_tokens\": 9,\\n'\n",
      " '              \"prompt_tokens\": 8,\\n'\n",
      " '              \"total_tokens\": 17\\n'\n",
      " '            },\\n'\n",
      " '            \"finish_reason\": \"stop\"\\n'\n",
      " '          }\\n'\n",
      " '        }\\n'\n",
      " '      ]\\n'\n",
      " '    }\\n'\n",
      " '  ]\\n'\n",
      " '}')\n"
     ]
    }
   ],
   "source": [
    "# Set Once and every call will create an AIConfig\n",
    "import openai\n",
    "from aiconfig.ChatCompletion import create_and_save_to_config\n",
    "# Set file path\n",
    "aiconfig_file_path = \"my-second-aiconfig.json\"\n",
    "openai.chat.completions.create  = create_and_save_to_config(config_file_path=aiconfig_file_path)\n",
    "\n",
    "# Basic Streaming Execution\n",
    "completion_params = {\n",
    "            \"model\": \"gpt-3.5-turbo\",\n",
    "            \"top_p\": 1,\n",
    "            \"max_tokens\": 3000,\n",
    "            \"temperature\": 1,\n",
    "            \"stream\": True,\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"content\": \"Tell me a riveting story\",\n",
    "                    \"role\": \"user\",\n",
    "                }\n",
    "            ],\n",
    "        }\n",
    "\n",
    "response = openai.chat.completions.create(**completion_params) # Creates a config saved to aiconfig_file_path = \"my-second-aiconfig.json\"\n",
    "print(\"Chat Completion Streaming Response: \")\n",
    "for iteration in response:\n",
    "    chunk = iteration.get(\"choices\",[{}])[0].get('delta',{}).get('content','')\n",
    "    print(chunk, end = '')\n",
    "\n",
    "\n",
    "print(\"\\nGenerated AIConfig Json: \")\n",
    "pretty_print_file('aiconfig.json')\n",
    "from openai import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated AIConfig Json: \n",
      "('{\\n'\n",
      " '  \"name\": \"\",\\n'\n",
      " '  \"schema_version\": \"latest\",\\n'\n",
      " '  \"metadata\": {\\n'\n",
      " '    \"parameters\": {},\\n'\n",
      " '    \"models\": {}\\n'\n",
      " '  },\\n'\n",
      " '  \"description\": \"\",\\n'\n",
      " '  \"prompts\": [\\n'\n",
      " '    {\\n'\n",
      " '      \"name\": \"prompt_0\",\\n'\n",
      " '      \"input\": \"Tell me a riveting story\",\\n'\n",
      " '      \"metadata\": {\\n'\n",
      " '        \"model\": {\\n'\n",
      " '          \"name\": \"gpt-3.5-turbo\",\\n'\n",
      " '          \"settings\": {\\n'\n",
      " '            \"model\": \"gpt-3.5-turbo\",\\n'\n",
      " '            \"top_p\": 1,\\n'\n",
      " '            \"max_tokens\": 3000,\\n'\n",
      " '            \"temperature\": 1,\\n'\n",
      " '            \"stream\": true\\n'\n",
      " '          }\\n'\n",
      " '        },\\n'\n",
      " '        \"parameters\": {},\\n'\n",
      " '        \"remember_chat_context\": true\\n'\n",
      " '      },\\n'\n",
      " '      \"outputs\": [\\n'\n",
      " '        {\\n'\n",
      " '          \"output_type\": \"execute_result\",\\n'\n",
      " '          \"execution_count\": 0,\\n'\n",
      " '          \"data\": {\\n'\n",
      " '            \"content\": \"Once upon a time, in a quaint little village nestled in the heart of a magical forest, lived a young boy named Oliver. '\n",
      " 'Oliver was an adventurous and curious soul, always seeking a new and thrilling experience. One day, while exploring the woods, he stumbled upon an '\n",
      " 'ancient, weathered map tucked inside a hollowed-out tree trunk.\\\\n\\\\nIntrigued by the mysterious markings on the map, Oliver decided to embark on '\n",
      " \"a quest to uncover the treasure it promised. With his loyal companion, a mischievous fox named Lily, by his side, they followed the map's \"\n",
      " 'directions, leading them deep into the heart of the forest.\\\\n\\\\nAs they ventured further, the forest became thicker, the air heavy with '\n",
      " 'enchantment. Suddenly, they stumbled upon an immense stone door adorned with intricate carvings and symbols. Eager to unlock the secrets beyond, '\n",
      " 'Oliver examined the map once more, looking for any clues.\\\\n\\\\nThe map indicated that to gain entry, they needed to collect three enchanted keys '\n",
      " 'hidden throughout the forest. Determined to prevail, Oliver and Lily set off on a series of thrilling and dangerous challenges, navigating through '\n",
      " 'treacherous swamps, scaling towering trees, and braving ferocious beasts that guarded the keys.\\\\n\\\\nTheir journey was arduous and fraught with '\n",
      " \"peril, but Oliver's unwavering determination and Lily's cleverness proved to be a powerful combination. They collected the first two keys, each \"\n",
      " 'unlocking a new path filled with wonders and dangers.\\\\n\\\\nFinally, they arrived at the final location, an ancient crumbling castle atop a '\n",
      " 'mountain. The last key awaited them, hidden amidst a labyrinth of dark tunnels and guarded by a fearsome dragon rumored to possess incredible '\n",
      " \"strength.\\\\n\\\\nUnfazed by the dragon's daunting presence, Oliver confronted it with bravery and a cunning plan. He distracted the dragon with \"\n",
      " \"Lily's playful antics while stealthily retrieving the key. As the dragon slumbered, they carefully made their escape, leaving the castle behind in \"\n",
      " 'awe of their feat.\\\\n\\\\nWith the three keys in their possession, Oliver and Lily raced back to the stone door, their hearts thundering with '\n",
      " 'excitement. As they inserted the keys into the corresponding keyholes, the door rumbled and groaned, magically coming to life, revealing a '\n",
      " \"dazzling treasure room glowing with gold and precious gems.\\\\n\\\\nOliver's eyes widened in awe as he discovered that the true treasure was not the \"\n",
      " 'material wealth before him, but the knowledge contained within ancient scrolls and artifacts lining the shelves. With newfound wisdom and tales to '\n",
      " 'share, Oliver and Lily returned to the village as heroes, forever changed by their extraordinary adventures.\\\\n\\\\nWord of their triumphs spread '\n",
      " 'far and wide, inspiring adventurers from all corners of the world to delve into the enchanted forest in search of their own destinies. And so, the '\n",
      " 'legend of Oliver and Lily lived on, reminding future generations about the power of courage, friendship, and the wonders hidden within our wildest '\n",
      " 'dreams.\",\\n'\n",
      " '            \"role\": \"assistant\"\\n'\n",
      " '          },\\n'\n",
      " '          \"metadata\": {\\n'\n",
      " '            \"finish_reason\": \"stop\"\\n'\n",
      " '          }\\n'\n",
      " '        }\\n'\n",
      " '      ]\\n'\n",
      " '    },\\n'\n",
      " '    {\\n'\n",
      " '      \"name\": \"prompt_1\",\\n'\n",
      " '      \"input\": \"Tell me a joke about apples\",\\n'\n",
      " '      \"metadata\": {\\n'\n",
      " '        \"model\": {\\n'\n",
      " '          \"name\": \"gpt-3.5-turbo\",\\n'\n",
      " '          \"settings\": {\\n'\n",
      " '            \"model\": \"gpt-3.5-turbo\",\\n'\n",
      " '            \"top_p\": 1,\\n'\n",
      " '            \"max_tokens\": 3000,\\n'\n",
      " '            \"temperature\": 1\\n'\n",
      " '          }\\n'\n",
      " '        },\\n'\n",
      " '        \"parameters\": {},\\n'\n",
      " '        \"remember_chat_context\": true\\n'\n",
      " '      },\\n'\n",
      " '      \"outputs\": [\\n'\n",
      " '        {\\n'\n",
      " '          \"output_type\": \"execute_result\",\\n'\n",
      " '          \"data\": {\\n'\n",
      " '            \"role\": \"assistant\",\\n'\n",
      " '            \"content\": \"Why did the apple go to school?\\\\n\\\\nBecause it wanted to be a \\\\\"smarty-pie\\\\\"!\"\\n'\n",
      " '          },\\n'\n",
      " '          \"metadata\": {}\\n'\n",
      " '        }\\n'\n",
      " '      ]\\n'\n",
      " '    },\\n'\n",
      " '    {\\n'\n",
      " '      \"name\": \"prompt_2\",\\n'\n",
      " '      \"input\": \"Tell this joke in a shakespearean rhetoric\",\\n'\n",
      " '      \"metadata\": {\\n'\n",
      " '        \"model\": {\\n'\n",
      " '          \"name\": \"gpt-3.5-turbo\",\\n'\n",
      " '          \"settings\": {\\n'\n",
      " '            \"model\": \"gpt-3.5-turbo\",\\n'\n",
      " '            \"top_p\": 1,\\n'\n",
      " '            \"max_tokens\": 3000,\\n'\n",
      " '            \"temperature\": 1\\n'\n",
      " '          }\\n'\n",
      " '        },\\n'\n",
      " '        \"parameters\": {},\\n'\n",
      " '        \"remember_chat_context\": true\\n'\n",
      " '      },\\n'\n",
      " '      \"outputs\": [\\n'\n",
      " '        {\\n'\n",
      " '          \"output_type\": \"execute_result\",\\n'\n",
      " '          \"execution_count\": 0,\\n'\n",
      " '          \"data\": {\\n'\n",
      " '            \"content\": \"Pray, dost thou know why thine apple embarked to school?\\\\n\\\\nForsooth, it sought to taste the sweet nectar of knowledge '\n",
      " 'and become a \\\\\"smarty-pie\\\\\"!\",\\n'\n",
      " '            \"role\": \"assistant\"\\n'\n",
      " '          },\\n'\n",
      " '          \"metadata\": {\\n'\n",
      " '            \"id\": \"chatcmpl-8Pgfm2CD8ZI38OhiIlkdtcFbQOfXi\",\\n'\n",
      " '            \"created\": 1701132926,\\n'\n",
      " '            \"model\": \"gpt-3.5-turbo-0613\",\\n'\n",
      " '            \"object\": \"chat.completion\",\\n'\n",
      " '            \"usage\": {\\n'\n",
      " '              \"completion_tokens\": 37,\\n'\n",
      " '              \"prompt_tokens\": 50,\\n'\n",
      " '              \"total_tokens\": 87\\n'\n",
      " '            },\\n'\n",
      " '            \"finish_reason\": \"stop\"\\n'\n",
      " '          }\\n'\n",
      " '        }\\n'\n",
      " '      ]\\n'\n",
      " '    }\\n'\n",
      " '  ]\\n'\n",
      " '}')\n"
     ]
    }
   ],
   "source": [
    "# Set Once and every call will create an AIConfig\n",
    "from aiconfig.Config import AIConfigRuntime\n",
    "import openai\n",
    "from aiconfig.ChatCompletion import create_and_save_to_config\n",
    "# Set aiconfig\n",
    "aiconfig = AIConfigRuntime.load(\"my-second-aiconfig.json\") # load the second aiconfig we just created and use it\n",
    "openai.chat.completions.create = create_and_save_to_config(aiconfig=aiconfig)\n",
    "\n",
    "# Compounded Execution\n",
    "completion_params = {\n",
    "            \"model\": \"gpt-3.5-turbo\",\n",
    "            \"top_p\": 1,\n",
    "            \"max_tokens\": 3000,\n",
    "            \"temperature\": 1,\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"content\": \"Tell me a joke about apples\",\n",
    "                    \"role\": \"user\",\n",
    "                }\n",
    "            ],\n",
    "        }\n",
    "\n",
    "response = openai.chat.completions.create(**completion_params) # Config was previously loaded from 'my-second-aiconfig.json. New Prompt gets added to the AIConfig Object and also saved to the same file\n",
    "\n",
    "completion_params = {\n",
    "            \"model\": \"gpt-3.5-turbo\",\n",
    "            \"top_p\": 1,\n",
    "            \"max_tokens\": 3000,\n",
    "            \"temperature\": 1,\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"content\": \"Tell me a joke about apples\",\n",
    "                    \"role\": \"user\",\n",
    "                },\n",
    "                 {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"Why did the apple go to school?\\n\\nBecause it wanted to be a \\\"smarty-pie\\\"!\"\n",
    "      },                                \n",
    "      {\n",
    "                    \"content\": \"Tell this joke in a shakespearean rhetoric\",\n",
    "                    \"role\": \"user\",\n",
    "                }\n",
    "            ],\n",
    "        }\n",
    "\n",
    "response = openai.chat.completions.create(**completion_params) # Config is updated with the second prompt keeping the history intact\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nGenerated AIConfig Json: \")\n",
    "pretty_print_file('my-second-aiconfig.json') # open the config yourself and check it out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-8PgfoEnPJi7X0azDcNH2ZhIVrgdrW', choices=[Choice(finish_reason='function_call', index=0, message=ChatCompletionMessage(content=None, role='assistant', function_call=FunctionCall(arguments='{\\n  \"location\": \"Boston, MA\"\\n}', name='get_current_weather'), tool_calls=None))], created=1701132928, model='gpt-3.5-turbo-0613', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=18, prompt_tokens=82, total_tokens=100))\n",
      "ChatCompletion(id='chatcmpl-8PgfpSm2wx9i2XOM351FMWwjtWzXN', choices=[Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='The weather in Boston is currently sunny with a temperature of 22 degrees Celsius.', role='assistant', function_call=None, tool_calls=None))], created=1701132929, model='gpt-3.5-turbo-0613', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=17, prompt_tokens=134, total_tokens=151))\n"
     ]
    }
   ],
   "source": [
    "# Function Call Capture\n",
    "# Set Once and every call will create an AIConfig\n",
    "from aiconfig.Config import AIConfigRuntime\n",
    "import openai\n",
    "from aiconfig.ChatCompletion import create_and_save_to_config\n",
    "# Set aiconfig\n",
    "openai.chat.completions.create = create_and_save_to_config(config_file_path='function_call.json')\n",
    "\n",
    "def get_current_weather(location, unit):\n",
    "    return { \"temperature\": 22, \"unit\": \"celsius\", \"description\": \"Sunny\" }\n",
    "\n",
    "completion_params = {\n",
    "    \"model\": \"gpt-3.5-turbo-0613\",\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"What is the weather like in Boston?\"}],\n",
    "    \"functions\": [\n",
    "        {\n",
    "            \"name\": \"get_current_weather\",\n",
    "            \"description\": \"Get the current weather in a given location\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                    },\n",
    "                    \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n",
    "                },\n",
    "                \"required\": [\"location\"],\n",
    "            },\n",
    "        }\n",
    "    ],\n",
    "}\n",
    "\n",
    "response = openai.chat.completions.create(**completion_params) \n",
    "\n",
    "function_call_response = get_current_weather(location=\"Boston\", unit=\"celsius\")\n",
    "print(response)\n",
    "\n",
    "completion_params = {\n",
    "  \"model\": \"gpt-3.5-turbo-0613\",\n",
    "  \"messages\": [\n",
    "    {\"role\": \"user\", \"content\": \"What is the weather like in Boston?\"},\n",
    "    {\"role\": \"assistant\", \"content\": 'null', \"function_call\": {\n",
    "          \"name\": \"get_current_weather\",\n",
    "          \"arguments\": \"{\\n  \\\"location\\\": \\\"Boston, MA\\\"\\n}\"\n",
    "        }},\n",
    "    {\"role\": \"function\", \"name\": \"get_current_weather\", \"content\": str(function_call_response)}\n",
    "\n",
    "  ],\n",
    "  \"functions\": [\n",
    "    {\n",
    "      \"name\": \"get_current_weather\",\n",
    "      \"description\": \"Get the current weather in a given location\",\n",
    "      \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "          \"location\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The city and state, e.g. San Francisco, CA\"\n",
    "          },\n",
    "          \"unit\": {\n",
    "            \"type\": \"string\",\n",
    "            \"enum\": [\"celsius\", \"fahrenheit\"]\n",
    "          }\n",
    "        },\n",
    "        \"required\": [\"location\"]\n",
    "      }\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n",
    "response = openai.chat.completions.create(**completion_params) \n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "# Instantiate a client\n",
    "from aiconfig.ChatCompletion import create_and_save_to_config\n",
    "\n",
    "client = openai.Client()\n",
    "client.chat.completions.create = create_and_save_to_config()\n",
    "\n",
    "completion_params = {\n",
    "            \"model\": \"gpt-3.5-turbo\",\n",
    "            \"top_p\": 1,\n",
    "            \"max_tokens\": 3000,\n",
    "            \"temperature\": 1,\n",
    "            \"stream\": False,\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"content\": \"Hi 2\",\n",
    "                    \"role\": \"user\",\n",
    "                }\n",
    "            ],\n",
    "        }\n",
    "response = client.chat.completions.create(**completion_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/aiconfig/lib/python3.10/site-packages/pydantic/_internal/_fields.py:149: UserWarning: Field \"model_parsers\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/aiconfig/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response=[ChatCompletionChunk(id='chatcmpl-8PgmnT5R8rL3MYcPvRypNwylzxwZj', choices=[Choice(delta=ChoiceDelta(content='', function_call=None, role='assistant', tool_calls=None), finish_reason=None, index=0)], created=1701133361, model='gpt-3.5-turbo-0613', object='chat.completion.chunk', system_fingerprint=None), ChatCompletionChunk(id='chatcmpl-8PgmnT5R8rL3MYcPvRypNwylzxwZj', choices=[Choice(delta=ChoiceDelta(content='Hello', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0)], created=1701133361, model='gpt-3.5-turbo-0613', object='chat.completion.chunk', system_fingerprint=None), ChatCompletionChunk(id='chatcmpl-8PgmnT5R8rL3MYcPvRypNwylzxwZj', choices=[Choice(delta=ChoiceDelta(content='!', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0)], created=1701133361, model='gpt-3.5-turbo-0613', object='chat.completion.chunk', system_fingerprint=None), ChatCompletionChunk(id='chatcmpl-8PgmnT5R8rL3MYcPvRypNwylzxwZj', choices=[Choice(delta=ChoiceDelta(content=' How', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0)], created=1701133361, model='gpt-3.5-turbo-0613', object='chat.completion.chunk', system_fingerprint=None), ChatCompletionChunk(id='chatcmpl-8PgmnT5R8rL3MYcPvRypNwylzxwZj', choices=[Choice(delta=ChoiceDelta(content=' can', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0)], created=1701133361, model='gpt-3.5-turbo-0613', object='chat.completion.chunk', system_fingerprint=None), ChatCompletionChunk(id='chatcmpl-8PgmnT5R8rL3MYcPvRypNwylzxwZj', choices=[Choice(delta=ChoiceDelta(content=' I', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0)], created=1701133361, model='gpt-3.5-turbo-0613', object='chat.completion.chunk', system_fingerprint=None), ChatCompletionChunk(id='chatcmpl-8PgmnT5R8rL3MYcPvRypNwylzxwZj', choices=[Choice(delta=ChoiceDelta(content=' assist', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0)], created=1701133361, model='gpt-3.5-turbo-0613', object='chat.completion.chunk', system_fingerprint=None), ChatCompletionChunk(id='chatcmpl-8PgmnT5R8rL3MYcPvRypNwylzxwZj', choices=[Choice(delta=ChoiceDelta(content=' you', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0)], created=1701133361, model='gpt-3.5-turbo-0613', object='chat.completion.chunk', system_fingerprint=None), ChatCompletionChunk(id='chatcmpl-8PgmnT5R8rL3MYcPvRypNwylzxwZj', choices=[Choice(delta=ChoiceDelta(content=' today', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0)], created=1701133361, model='gpt-3.5-turbo-0613', object='chat.completion.chunk', system_fingerprint=None), ChatCompletionChunk(id='chatcmpl-8PgmnT5R8rL3MYcPvRypNwylzxwZj', choices=[Choice(delta=ChoiceDelta(content='?', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0)], created=1701133361, model='gpt-3.5-turbo-0613', object='chat.completion.chunk', system_fingerprint=None), ChatCompletionChunk(id='chatcmpl-8PgmnT5R8rL3MYcPvRypNwylzxwZj', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, role=None, tool_calls=None), finish_reason='stop', index=0)], created=1701133361, model='gpt-3.5-turbo-0613', object='chat.completion.chunk', system_fingerprint=None)]\n",
      "Hello! How can I assist you today?"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[ExecuteResult(output_type='execute_result', execution_count=0, data={'content': 'Hello! How can I assist you today?', 'role': 'assistant'}, mime_type=None, metadata={'finish_reason': 'stop'})]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from aiconfig import AIConfigRuntime\n",
    "from aiconfig import InferenceOptions\n",
    "import openai\n",
    "\n",
    "config = AIConfigRuntime.load(\"aiconfig.json\")\n",
    "inference_options = InferenceOptions()\n",
    "await config.run(\"prompt_0\", options = inference_options)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
