{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Api Key\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "original_create = openai.chat.completions.create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "\n",
    "def pretty_print_file(file_name):\n",
    "    with open(file_name, 'r') as f:\n",
    "        pp = pprint.PrettyPrinter(indent=4, width = 150)\n",
    "        pp.pprint(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/pydantic/_internal/_fields.py:128: UserWarning: Field \"model_parsers\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat Completion Response: \n",
      "ChatCompletion(id='chatcmpl-8Phj9uWHgtWC3RgMkoKioiLyS2Kpf', choices=[Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Hello! How can I assist you today?', role='assistant', function_call=None, tool_calls=None))], created=1701136979, model='gpt-3.5-turbo-0613', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=9, prompt_tokens=8, total_tokens=17))\n",
      "\n",
      "Generated AIConfig Json: \n",
      "('{\\n'\n",
      " '  \"name\": \"\",\\n'\n",
      " '  \"schema_version\": \"latest\",\\n'\n",
      " '  \"metadata\": {\\n'\n",
      " '    \"parameters\": {},\\n'\n",
      " '    \"models\": {}\\n'\n",
      " '  },\\n'\n",
      " '  \"description\": \"\",\\n'\n",
      " '  \"prompts\": [\\n'\n",
      " '    {\\n'\n",
      " '      \"name\": \"prompt_0\",\\n'\n",
      " '      \"input\": \"Hi\",\\n'\n",
      " '      \"metadata\": {\\n'\n",
      " '        \"model\": {\\n'\n",
      " '          \"name\": \"gpt-3.5-turbo\",\\n'\n",
      " '          \"settings\": {\\n'\n",
      " '            \"model\": \"gpt-3.5-turbo\",\\n'\n",
      " '            \"top_p\": 1,\\n'\n",
      " '            \"max_tokens\": 3000,\\n'\n",
      " '            \"temperature\": 1,\\n'\n",
      " '            \"stream\": false\\n'\n",
      " '          }\\n'\n",
      " '        },\\n'\n",
      " '        \"parameters\": {},\\n'\n",
      " '        \"remember_chat_context\": true\\n'\n",
      " '      },\\n'\n",
      " '      \"outputs\": [\\n'\n",
      " '        {\\n'\n",
      " '          \"output_type\": \"execute_result\",\\n'\n",
      " '          \"execution_count\": 0,\\n'\n",
      " '          \"data\": {\\n'\n",
      " '            \"content\": \"Hello! How can I assist you today?\",\\n'\n",
      " '            \"role\": \"assistant\"\\n'\n",
      " '          },\\n'\n",
      " '          \"metadata\": {\\n'\n",
      " '            \"id\": \"chatcmpl-8Phj9uWHgtWC3RgMkoKioiLyS2Kpf\",\\n'\n",
      " '            \"created\": 1701136979,\\n'\n",
      " '            \"model\": \"gpt-3.5-turbo-0613\",\\n'\n",
      " '            \"object\": \"chat.completion\",\\n'\n",
      " '            \"usage\": {\\n'\n",
      " '              \"completion_tokens\": 9,\\n'\n",
      " '              \"prompt_tokens\": 8,\\n'\n",
      " '              \"total_tokens\": 17\\n'\n",
      " '            },\\n'\n",
      " '            \"finish_reason\": \"stop\"\\n'\n",
      " '          }\\n'\n",
      " '        }\\n'\n",
      " '      ]\\n'\n",
      " '    }\\n'\n",
      " '  ]\\n'\n",
      " '}')\n"
     ]
    }
   ],
   "source": [
    "# Set Once and every call will create an AIConfig\n",
    "import openai\n",
    "from aiconfig.ChatCompletion import create_and_save_to_config\n",
    "openai.chat.completions.create = create_and_save_to_config()\n",
    "\n",
    "# Basic Execution\n",
    "completion_params = {\n",
    "            \"model\": \"gpt-3.5-turbo\",\n",
    "            \"top_p\": 1,\n",
    "            \"max_tokens\": 3000,\n",
    "            \"temperature\": 1,\n",
    "            \"stream\": False,\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"content\": \"Hi\",\n",
    "                    \"role\": \"user\",\n",
    "                }\n",
    "            ],\n",
    "        }\n",
    "\n",
    "response = openai.chat.completions.create(**completion_params) # Creates a config saved to default path `aiconfig.json`\n",
    "print(\"Chat Completion Response: \")\n",
    "pprint.pprint(response)\n",
    "\n",
    "print(\"\\nGenerated AIConfig Json: \")\n",
    "pretty_print_file('aiconfig.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat Completion Streaming Response: \n",
      "Once upon a time, in a quaint little village nestled at the foot of a great mountain, there lived a young girl named Lily. Lily was known for her adventurous spirit and unstoppable curiosity. She had heard tales of a majestic waterfall hidden deep within the heart of the mountains, a place where the water flowed in shades of blue and where magical creatures were said to dwell.\n",
      "\n",
      "Determined to uncover the truth behind these enchanting rumors, Lily embarked on a perilous journey into the unknown. Armed with her hiking gear and an unwavering determination, she set out to explore the uncharted territories of the mountains.\n",
      "\n",
      "As she trekked deeper into the wilderness, the landscape transformed into a breathtaking paradise. Lush green forests surrounded her, and the scent of wildflowers filled the air. Birds sang joyfully overhead, guiding her through the winding trails.\n",
      "\n",
      "Days turned into weeks, and Lily faced various obstacles along the way. She had to navigate treacherous cliffs, cross roaring rivers, and brave unpredictable weather conditions. But she remained undeterred, fueled by the stories she had heard and the beauty she knew awaited her.\n",
      "\n",
      "Finally, after weeks of tireless trekking, she heard the distant roar of falling water. Her heart raced with anticipation as she followed the sound, pushing through thick foliage and branches. And then, there it was — the magnificent waterfall she had dreamed of for so long.\n",
      "\n",
      "The water sparkled under the golden rays of the sun, cascading down the mountainside in a mesmerizing display. The pool beneath the waterfall glowed with a magical hue, as if touched by the very essence of nature itself.\n",
      "\n",
      "But to Lily's surprise, she didn't find any magical creatures dwelling there. Instead, she discovered something far more extraordinary. In the crystal-clear waters, she saw her own reflection, her eyes gleaming with a newfound realization.\n",
      "\n",
      "It was in that moment that Lily understood the true magic of the waterfall. It wasn't just about the mythical creatures or the breathtaking beauty—it was about the strength and resilience she had discovered within herself. She had conquered her fears, battled against nature, and emerged victorious.\n",
      "\n",
      "Word of her incredible journey spread throughout the village, and Lily became a symbol of bravery and adventure. People flocked to the mountains, inspired by her tale, each seeking their own personal discoveries and triumphs.\n",
      "\n",
      "And so, the village flourished, its people finding solace and inspiration in the mountains that held the remarkable waterfall. Lily's story continued to be told for generations, reminding all who listened that the greatest adventures are often found in the pursuit of our dreams and the exploration of the unknown.None\n",
      "Generated AIConfig Json: \n",
      "('{\\n'\n",
      " '  \"name\": \"\",\\n'\n",
      " '  \"schema_version\": \"latest\",\\n'\n",
      " '  \"metadata\": {\\n'\n",
      " '    \"parameters\": {},\\n'\n",
      " '    \"models\": {}\\n'\n",
      " '  },\\n'\n",
      " '  \"description\": \"\",\\n'\n",
      " '  \"prompts\": [\\n'\n",
      " '    {\\n'\n",
      " '      \"name\": \"prompt_0\",\\n'\n",
      " '      \"input\": \"Hi\",\\n'\n",
      " '      \"metadata\": {\\n'\n",
      " '        \"model\": {\\n'\n",
      " '          \"name\": \"gpt-3.5-turbo\",\\n'\n",
      " '          \"settings\": {\\n'\n",
      " '            \"model\": \"gpt-3.5-turbo\",\\n'\n",
      " '            \"top_p\": 1,\\n'\n",
      " '            \"max_tokens\": 3000,\\n'\n",
      " '            \"temperature\": 1,\\n'\n",
      " '            \"stream\": false\\n'\n",
      " '          }\\n'\n",
      " '        },\\n'\n",
      " '        \"parameters\": {},\\n'\n",
      " '        \"remember_chat_context\": true\\n'\n",
      " '      },\\n'\n",
      " '      \"outputs\": [\\n'\n",
      " '        {\\n'\n",
      " '          \"output_type\": \"execute_result\",\\n'\n",
      " '          \"execution_count\": 0,\\n'\n",
      " '          \"data\": {\\n'\n",
      " '            \"content\": \"Hello! How can I assist you today?\",\\n'\n",
      " '            \"role\": \"assistant\"\\n'\n",
      " '          },\\n'\n",
      " '          \"metadata\": {\\n'\n",
      " '            \"id\": \"chatcmpl-8Phj9uWHgtWC3RgMkoKioiLyS2Kpf\",\\n'\n",
      " '            \"created\": 1701136979,\\n'\n",
      " '            \"model\": \"gpt-3.5-turbo-0613\",\\n'\n",
      " '            \"object\": \"chat.completion\",\\n'\n",
      " '            \"usage\": {\\n'\n",
      " '              \"completion_tokens\": 9,\\n'\n",
      " '              \"prompt_tokens\": 8,\\n'\n",
      " '              \"total_tokens\": 17\\n'\n",
      " '            },\\n'\n",
      " '            \"finish_reason\": \"stop\"\\n'\n",
      " '          }\\n'\n",
      " '        }\\n'\n",
      " '      ]\\n'\n",
      " '    }\\n'\n",
      " '  ]\\n'\n",
      " '}')\n"
     ]
    }
   ],
   "source": [
    "# Set Once and every call will create an AIConfig\n",
    "import openai\n",
    "from aiconfig.ChatCompletion import create_and_save_to_config\n",
    "# Set file path\n",
    "aiconfig_file_path = \"my-second-aiconfig.json\"\n",
    "openai.chat.completions.create  = create_and_save_to_config(config_file_path=aiconfig_file_path)\n",
    "\n",
    "# Basic Streaming Execution\n",
    "completion_params = {\n",
    "            \"model\": \"gpt-3.5-turbo\",\n",
    "            \"top_p\": 1,\n",
    "            \"max_tokens\": 3000,\n",
    "            \"temperature\": 1,\n",
    "            \"stream\": True,\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"content\": \"Tell me a riveting story\",\n",
    "                    \"role\": \"user\",\n",
    "                }\n",
    "            ],\n",
    "        }\n",
    "\n",
    "response = openai.chat.completions.create(**completion_params) # Creates a config saved to aiconfig_file_path = \"my-second-aiconfig.json\"\n",
    "print(\"Chat Completion Streaming Response: \")\n",
    "for iteration in response:\n",
    "    iteration_dict = iteration.model_dump()\n",
    "    chunk = iteration_dict.get(\"choices\",[{}])[0].get('delta',{}).get('content','')\n",
    "    print(chunk, end = '')\n",
    "\n",
    "\n",
    "print(\"\\nGenerated AIConfig Json: \")\n",
    "pretty_print_file('aiconfig.json')\n",
    "from openai import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated AIConfig Json: \n",
      "('{\\n'\n",
      " '  \"name\": \"\",\\n'\n",
      " '  \"schema_version\": \"latest\",\\n'\n",
      " '  \"metadata\": {\\n'\n",
      " '    \"parameters\": {},\\n'\n",
      " '    \"models\": {}\\n'\n",
      " '  },\\n'\n",
      " '  \"description\": \"\",\\n'\n",
      " '  \"prompts\": [\\n'\n",
      " '    {\\n'\n",
      " '      \"name\": \"prompt_0\",\\n'\n",
      " '      \"input\": \"Tell me a riveting story\",\\n'\n",
      " '      \"metadata\": {\\n'\n",
      " '        \"model\": {\\n'\n",
      " '          \"name\": \"gpt-3.5-turbo\",\\n'\n",
      " '          \"settings\": {\\n'\n",
      " '            \"model\": \"gpt-3.5-turbo\",\\n'\n",
      " '            \"top_p\": 1,\\n'\n",
      " '            \"max_tokens\": 3000,\\n'\n",
      " '            \"temperature\": 1,\\n'\n",
      " '            \"stream\": true\\n'\n",
      " '          }\\n'\n",
      " '        },\\n'\n",
      " '        \"parameters\": {},\\n'\n",
      " '        \"remember_chat_context\": true\\n'\n",
      " '      },\\n'\n",
      " '      \"outputs\": [\\n'\n",
      " '        {\\n'\n",
      " '          \"output_type\": \"execute_result\",\\n'\n",
      " '          \"execution_count\": 0,\\n'\n",
      " '          \"data\": {\\n'\n",
      " '            \"content\": \"Once upon a time, in a quaint little village nestled at the foot of a great mountain, there lived a young girl named Lily. '\n",
      " 'Lily was known for her adventurous spirit and unstoppable curiosity. She had heard tales of a majestic waterfall hidden deep within the heart of '\n",
      " 'the mountains, a place where the water flowed in shades of blue and where magical creatures were said to dwell.\\\\n\\\\nDetermined to uncover the '\n",
      " 'truth behind these enchanting rumors, Lily embarked on a perilous journey into the unknown. Armed with her hiking gear and an unwavering '\n",
      " 'determination, she set out to explore the uncharted territories of the mountains.\\\\n\\\\nAs she trekked deeper into the wilderness, the landscape '\n",
      " 'transformed into a breathtaking paradise. Lush green forests surrounded her, and the scent of wildflowers filled the air. Birds sang joyfully '\n",
      " 'overhead, guiding her through the winding trails.\\\\n\\\\nDays turned into weeks, and Lily faced various obstacles along the way. She had to navigate '\n",
      " 'treacherous cliffs, cross roaring rivers, and brave unpredictable weather conditions. But she remained undeterred, fueled by the stories she had '\n",
      " 'heard and the beauty she knew awaited her.\\\\n\\\\nFinally, after weeks of tireless trekking, she heard the distant roar of falling water. Her heart '\n",
      " 'raced with anticipation as she followed the sound, pushing through thick foliage and branches. And then, there it was \\\\u2014 the magnificent '\n",
      " 'waterfall she had dreamed of for so long.\\\\n\\\\nThe water sparkled under the golden rays of the sun, cascading down the mountainside in a '\n",
      " 'mesmerizing display. The pool beneath the waterfall glowed with a magical hue, as if touched by the very essence of nature itself.\\\\n\\\\nBut to '\n",
      " \"Lily's surprise, she didn't find any magical creatures dwelling there. Instead, she discovered something far more extraordinary. In the \"\n",
      " 'crystal-clear waters, she saw her own reflection, her eyes gleaming with a newfound realization.\\\\n\\\\nIt was in that moment that Lily understood '\n",
      " \"the true magic of the waterfall. It wasn't just about the mythical creatures or the breathtaking beauty\\\\u2014it was about the strength and \"\n",
      " 'resilience she had discovered within herself. She had conquered her fears, battled against nature, and emerged victorious.\\\\n\\\\nWord of her '\n",
      " 'incredible journey spread throughout the village, and Lily became a symbol of bravery and adventure. People flocked to the mountains, inspired by '\n",
      " 'her tale, each seeking their own personal discoveries and triumphs.\\\\n\\\\nAnd so, the village flourished, its people finding solace and inspiration '\n",
      " \"in the mountains that held the remarkable waterfall. Lily's story continued to be told for generations, reminding all who listened that the \"\n",
      " 'greatest adventures are often found in the pursuit of our dreams and the exploration of the unknown.\",\\n'\n",
      " '            \"role\": \"assistant\"\\n'\n",
      " '          },\\n'\n",
      " '          \"metadata\": {\\n'\n",
      " '            \"finish_reason\": \"stop\"\\n'\n",
      " '          }\\n'\n",
      " '        }\\n'\n",
      " '      ]\\n'\n",
      " '    },\\n'\n",
      " '    {\\n'\n",
      " '      \"name\": \"prompt_1\",\\n'\n",
      " '      \"input\": \"Tell me a joke about apples\",\\n'\n",
      " '      \"metadata\": {\\n'\n",
      " '        \"model\": {\\n'\n",
      " '          \"name\": \"gpt-3.5-turbo\",\\n'\n",
      " '          \"settings\": {\\n'\n",
      " '            \"model\": \"gpt-3.5-turbo\",\\n'\n",
      " '            \"top_p\": 1,\\n'\n",
      " '            \"max_tokens\": 3000,\\n'\n",
      " '            \"temperature\": 1\\n'\n",
      " '          }\\n'\n",
      " '        },\\n'\n",
      " '        \"parameters\": {},\\n'\n",
      " '        \"remember_chat_context\": true\\n'\n",
      " '      },\\n'\n",
      " '      \"outputs\": [\\n'\n",
      " '        {\\n'\n",
      " '          \"output_type\": \"execute_result\",\\n'\n",
      " '          \"data\": {\\n'\n",
      " '            \"role\": \"assistant\",\\n'\n",
      " '            \"content\": \"Why did the apple go to school?\\\\n\\\\nBecause it wanted to be a \\\\\"smarty-pie\\\\\"!\"\\n'\n",
      " '          },\\n'\n",
      " '          \"metadata\": {}\\n'\n",
      " '        }\\n'\n",
      " '      ]\\n'\n",
      " '    },\\n'\n",
      " '    {\\n'\n",
      " '      \"name\": \"prompt_2\",\\n'\n",
      " '      \"input\": \"Tell this joke in a shakespearean rhetoric\",\\n'\n",
      " '      \"metadata\": {\\n'\n",
      " '        \"model\": {\\n'\n",
      " '          \"name\": \"gpt-3.5-turbo\",\\n'\n",
      " '          \"settings\": {\\n'\n",
      " '            \"model\": \"gpt-3.5-turbo\",\\n'\n",
      " '            \"top_p\": 1,\\n'\n",
      " '            \"max_tokens\": 3000,\\n'\n",
      " '            \"temperature\": 1\\n'\n",
      " '          }\\n'\n",
      " '        },\\n'\n",
      " '        \"parameters\": {},\\n'\n",
      " '        \"remember_chat_context\": true\\n'\n",
      " '      },\\n'\n",
      " '      \"outputs\": [\\n'\n",
      " '        {\\n'\n",
      " '          \"output_type\": \"execute_result\",\\n'\n",
      " '          \"execution_count\": 0,\\n'\n",
      " '          \"data\": {\\n'\n",
      " '            \"content\": \"Pray, hear ye, a merry jest \\'bout yonder apple!\\\\nWherefore did the apple embark upon a scholarly pursuit?\\\\nForsooth, to '\n",
      " 'don a cap of wizdom, it didst commute!\\\\n\\\\nForsooth, \\'twas craving to be a \\\\\"smarty-pie\\\\\", verily,\\\\nTo soaketh in the knowledge, and '\n",
      " 'fruitfully multiply!\\\\n\",\\n'\n",
      " '            \"role\": \"assistant\"\\n'\n",
      " '          },\\n'\n",
      " '          \"metadata\": {\\n'\n",
      " '            \"id\": \"chatcmpl-8PhjMuUh9fB8fKbLi0Q1BDWppp9An\",\\n'\n",
      " '            \"created\": 1701136992,\\n'\n",
      " '            \"model\": \"gpt-3.5-turbo-0613\",\\n'\n",
      " '            \"object\": \"chat.completion\",\\n'\n",
      " '            \"usage\": {\\n'\n",
      " '              \"completion_tokens\": 75,\\n'\n",
      " '              \"prompt_tokens\": 50,\\n'\n",
      " '              \"total_tokens\": 125\\n'\n",
      " '            },\\n'\n",
      " '            \"finish_reason\": \"stop\"\\n'\n",
      " '          }\\n'\n",
      " '        }\\n'\n",
      " '      ]\\n'\n",
      " '    }\\n'\n",
      " '  ]\\n'\n",
      " '}')\n"
     ]
    }
   ],
   "source": [
    "# Set Once and every call will create an AIConfig\n",
    "from aiconfig.Config import AIConfigRuntime\n",
    "import openai\n",
    "from aiconfig.ChatCompletion import create_and_save_to_config\n",
    "# Set aiconfig\n",
    "aiconfig = AIConfigRuntime.load(\"my-second-aiconfig.json\") # load the second aiconfig we just created and use it\n",
    "openai.chat.completions.create = create_and_save_to_config(aiconfig=aiconfig)\n",
    "\n",
    "# Compounded Execution\n",
    "completion_params = {\n",
    "            \"model\": \"gpt-3.5-turbo\",\n",
    "            \"top_p\": 1,\n",
    "            \"max_tokens\": 3000,\n",
    "            \"temperature\": 1,\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"content\": \"Tell me a joke about apples\",\n",
    "                    \"role\": \"user\",\n",
    "                }\n",
    "            ],\n",
    "        }\n",
    "\n",
    "response = openai.chat.completions.create(**completion_params) # Config was previously loaded from 'my-second-aiconfig.json. New Prompt gets added to the AIConfig Object and also saved to the same file\n",
    "\n",
    "completion_params = {\n",
    "            \"model\": \"gpt-3.5-turbo\",\n",
    "            \"top_p\": 1,\n",
    "            \"max_tokens\": 3000,\n",
    "            \"temperature\": 1,\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"content\": \"Tell me a joke about apples\",\n",
    "                    \"role\": \"user\",\n",
    "                },\n",
    "                 {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"Why did the apple go to school?\\n\\nBecause it wanted to be a \\\"smarty-pie\\\"!\"\n",
    "      },                                \n",
    "      {\n",
    "                    \"content\": \"Tell this joke in a shakespearean rhetoric\",\n",
    "                    \"role\": \"user\",\n",
    "                }\n",
    "            ],\n",
    "        }\n",
    "\n",
    "response = openai.chat.completions.create(**completion_params) # Config is updated with the second prompt keeping the history intact\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nGenerated AIConfig Json: \")\n",
    "pretty_print_file('my-second-aiconfig.json') # open the config yourself and check it out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-8PhjONQjlAD9FlewlvkJ6VnOe2eWk', choices=[Choice(finish_reason='function_call', index=0, message=ChatCompletionMessage(content=None, role='assistant', function_call=FunctionCall(arguments='{\\n  \"location\": \"Boston, MA\"\\n}', name='get_current_weather'), tool_calls=None))], created=1701136994, model='gpt-3.5-turbo-0613', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=18, prompt_tokens=82, total_tokens=100))\n",
      "ChatCompletion(id='chatcmpl-8PhjPhstfAe2IZCmm6usNSjKfrdmD', choices=[Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='The current weather in Boston is sunny with a temperature of 22 degrees Celsius.', role='assistant', function_call=None, tool_calls=None))], created=1701136995, model='gpt-3.5-turbo-0613', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=17, prompt_tokens=134, total_tokens=151))\n"
     ]
    }
   ],
   "source": [
    "# Function Call Capture\n",
    "# Set Once and every call will create an AIConfig\n",
    "from aiconfig.Config import AIConfigRuntime\n",
    "import openai\n",
    "from aiconfig.ChatCompletion import create_and_save_to_config\n",
    "# Set aiconfig\n",
    "openai.chat.completions.create = create_and_save_to_config(config_file_path='function_call.json')\n",
    "\n",
    "def get_current_weather(location, unit):\n",
    "    return { \"temperature\": 22, \"unit\": \"celsius\", \"description\": \"Sunny\" }\n",
    "\n",
    "completion_params = {\n",
    "    \"model\": \"gpt-3.5-turbo-0613\",\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"What is the weather like in Boston?\"}],\n",
    "    \"functions\": [\n",
    "        {\n",
    "            \"name\": \"get_current_weather\",\n",
    "            \"description\": \"Get the current weather in a given location\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                    },\n",
    "                    \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n",
    "                },\n",
    "                \"required\": [\"location\"],\n",
    "            },\n",
    "        }\n",
    "    ],\n",
    "}\n",
    "\n",
    "response = openai.chat.completions.create(**completion_params) \n",
    "\n",
    "function_call_response = get_current_weather(location=\"Boston\", unit=\"celsius\")\n",
    "print(response)\n",
    "\n",
    "completion_params = {\n",
    "  \"model\": \"gpt-3.5-turbo-0613\",\n",
    "  \"messages\": [\n",
    "    {\"role\": \"user\", \"content\": \"What is the weather like in Boston?\"},\n",
    "    {\"role\": \"assistant\", \"content\": 'null', \"function_call\": {\n",
    "          \"name\": \"get_current_weather\",\n",
    "          \"arguments\": \"{\\n  \\\"location\\\": \\\"Boston, MA\\\"\\n}\"\n",
    "        }},\n",
    "    {\"role\": \"function\", \"name\": \"get_current_weather\", \"content\": str(function_call_response)}\n",
    "\n",
    "  ],\n",
    "  \"functions\": [\n",
    "    {\n",
    "      \"name\": \"get_current_weather\",\n",
    "      \"description\": \"Get the current weather in a given location\",\n",
    "      \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "          \"location\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The city and state, e.g. San Francisco, CA\"\n",
    "          },\n",
    "          \"unit\": {\n",
    "            \"type\": \"string\",\n",
    "            \"enum\": [\"celsius\", \"fahrenheit\"]\n",
    "          }\n",
    "        },\n",
    "        \"required\": [\"location\"]\n",
    "      }\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n",
    "response = openai.chat.completions.create(**completion_params) \n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "# Instantiate a client\n",
    "from aiconfig.ChatCompletion import create_and_save_to_config\n",
    "\n",
    "client = openai.Client()\n",
    "client.chat.completions.create = create_and_save_to_config()\n",
    "\n",
    "completion_params = {\n",
    "            \"model\": \"gpt-3.5-turbo\",\n",
    "            \"top_p\": 1,\n",
    "            \"max_tokens\": 3000,\n",
    "            \"temperature\": 1,\n",
    "            \"stream\": False,\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"content\": \"Hi 2\",\n",
    "                    \"role\": \"user\",\n",
    "                }\n",
    "            ],\n",
    "        }\n",
    "response = client.chat.completions.create(**completion_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! How can I assist you today?"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[ExecuteResult(output_type='execute_result', execution_count=0, data={'content': 'Hello! How can I assist you today?', 'role': 'assistant'}, mime_type=None, metadata={'finish_reason': 'stop'})]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from aiconfig import AIConfigRuntime\n",
    "from aiconfig import InferenceOptions\n",
    "import openai\n",
    "# Reset Chat Completion to Original\n",
    "from aiconfig.ChatCompletion import openai_chat_completion_create\n",
    "# from aiconfig.ChatCompletion import create_and_save_to_config\n",
    "# openai.chat.completions.create =  create_and_save_to_config\n",
    "\n",
    "\n",
    "config = AIConfigRuntime.load(\"aiconfig.json\")\n",
    "inference_options = InferenceOptions()\n",
    "await config.run(\"prompt_0\", options = inference_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
