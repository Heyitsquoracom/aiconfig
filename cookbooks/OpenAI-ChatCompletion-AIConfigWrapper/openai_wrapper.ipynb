{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Api Key\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "\n",
    "def pretty_print_file(file_name):\n",
    "    with open(file_name, 'r') as f:\n",
    "        pp = pprint.PrettyPrinter(indent=4, width = 150)\n",
    "        pp.pprint(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/pydantic/_internal/_fields.py:128: UserWarning: Field \"model_parsers\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat Completion Response: \n",
      "<OpenAIObject chat.completion id=chatcmpl-8JbiPv2r26BGtJncNe33UnEyQrxOW at 0x11a38dbb0> JSON: {\n",
      "  \"id\": \"chatcmpl-8JbiPv2r26BGtJncNe33UnEyQrxOW\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1699683901,\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"Hello! How can I assist you today?\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 8,\n",
      "    \"completion_tokens\": 9,\n",
      "    \"total_tokens\": 17\n",
      "  }\n",
      "}\n",
      "\n",
      "Generated AIConfig Json: \n",
      "('{\\n'\n",
      " '  \"name\": \"\",\\n'\n",
      " '  \"schema_version\": \"latest\",\\n'\n",
      " '  \"metadata\": {\\n'\n",
      " '    \"parameters\": {},\\n'\n",
      " '    \"models\": {}\\n'\n",
      " '  },\\n'\n",
      " '  \"description\": \"\",\\n'\n",
      " '  \"prompts\": [\\n'\n",
      " '    {\\n'\n",
      " '      \"name\": \"prompt_0\",\\n'\n",
      " '      \"input\": \"Hi\",\\n'\n",
      " '      \"metadata\": {\\n'\n",
      " '        \"model\": {\\n'\n",
      " '          \"name\": \"gpt-3.5-turbo\",\\n'\n",
      " '          \"settings\": {\\n'\n",
      " '            \"model\": \"gpt-3.5-turbo\",\\n'\n",
      " '            \"top_p\": 1,\\n'\n",
      " '            \"max_tokens\": 3000,\\n'\n",
      " '            \"temperature\": 1,\\n'\n",
      " '            \"stream\": false\\n'\n",
      " '          }\\n'\n",
      " '        },\\n'\n",
      " '        \"parameters\": {},\\n'\n",
      " '        \"remember_chat_context\": true\\n'\n",
      " '      },\\n'\n",
      " '      \"outputs\": [\\n'\n",
      " '        {\\n'\n",
      " '          \"output_type\": \"execute_result\",\\n'\n",
      " '          \"execution_count\": 0,\\n'\n",
      " '          \"data\": {\\n'\n",
      " '            \"role\": \"assistant\",\\n'\n",
      " '            \"content\": \"Hello! How can I assist you today?\"\\n'\n",
      " '          },\\n'\n",
      " '          \"metadata\": {\\n'\n",
      " '            \"id\": \"chatcmpl-8JbiPv2r26BGtJncNe33UnEyQrxOW\",\\n'\n",
      " '            \"object\": \"chat.completion\",\\n'\n",
      " '            \"created\": 1699683901,\\n'\n",
      " '            \"model\": \"gpt-3.5-turbo-0613\",\\n'\n",
      " '            \"usage\": {\\n'\n",
      " '              \"prompt_tokens\": 8,\\n'\n",
      " '              \"completion_tokens\": 9,\\n'\n",
      " '              \"total_tokens\": 17\\n'\n",
      " '            },\\n'\n",
      " '            \"finish_reason\": \"stop\"\\n'\n",
      " '          }\\n'\n",
      " '        }\\n'\n",
      " '      ]\\n'\n",
      " '    }\\n'\n",
      " '  ]\\n'\n",
      " '}')\n"
     ]
    }
   ],
   "source": [
    "# Set Once and every call will create an AIConfig\n",
    "import openai\n",
    "from aiconfig.ChatCompletion import create_and_save_to_config\n",
    "openai.ChatCompletion.create = create_and_save_to_config()\n",
    "\n",
    "# Basic Execution\n",
    "completion_params = {\n",
    "            \"model\": \"gpt-3.5-turbo\",\n",
    "            \"top_p\": 1,\n",
    "            \"max_tokens\": 3000,\n",
    "            \"temperature\": 1,\n",
    "            \"stream\": False,\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"content\": \"Hi\",\n",
    "                    \"role\": \"user\",\n",
    "                }\n",
    "            ],\n",
    "        }\n",
    "\n",
    "response = openai.ChatCompletion.create(**completion_params) # Creates a config saved to default path `aiconfig.json`\n",
    "print(\"Chat Completion Response: \")\n",
    "pprint.pprint(response)\n",
    "\n",
    "print(\"\\nGenerated AIConfig Json: \")\n",
    "pretty_print_file('aiconfig.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat Completion Streaming Response: \n",
      "Once upon a time, in a small village named Willowbrook, there lived a young girl named Eliza. She was known for her boundless curiosity and adventurous spirit, often spending her days exploring the nearby forest with her loyal companion, a mischievous fox named Jasper.\n",
      "\n",
      "One sunny morning, as Eliza set out into the woods, she discovered a hidden path she had never seen before. Filled with excitement, she followed the trail and soon found herself in a clearing unlike anything she had ever seen. In the center stood an ancient-looking tree with pulsating, glowing roots that seemed to emanate a mysterious energy.\n",
      "\n",
      "Driven by curiosity, Eliza reached out to touch the roots of the enchanted tree. In a whirlwind of shimmering lights, she suddenly found herself transported to a distant land, far away from her familiar village.\n",
      "\n",
      "In this new realm, Eliza discovered a breathtaking kingdom known as Etherealis. The kingdom was on the verge of despair, as an evil sorceress named Morgana had cast a dark curse that drained the happiness and hope from its inhabitants. The once-vibrant kingdom now lay in gloom, with the people living in constant fear and sadness.\n",
      "\n",
      "Determined to bring back joy to Etherealis, Eliza embarked on a quest to find the fabled Crystal of Dreams, a powerful relic said to possess the ability to restore happiness to the kingdom. Joined by her faithful friend Jasper, Eliza faced perilous challenges, encountered magical creatures, and made new allies along the way.\n",
      "\n",
      "As her journey became more treacherous and Morgana's minions grew more formidable, Eliza's courage and determination grew stronger. Through her unwavering spirit, she inspired the people of Etherealis to rise up and reclaim their kingdom from the clutches of despair.\n",
      "\n",
      "After countless trials and sacrifices, Eliza finally reached the heart of Morgana's lair, where the Crystal of Dreams awaited. With a fierce battle of wits and bravery, Eliza managed to overcome Morgana's dark powers and shatter the curse that had plagued Etherealis.\n",
      "\n",
      "As the curse broke, the land became bathed in a brilliant light, and joy swept through the kingdom like a gentle breeze. The once-despondent villagers emerged from their homes, their faces aglow with renewed hope.\n",
      "\n",
      "Eliza, hailed as the champion of Etherealis, was celebrated by the grateful townspeople. Her name became legendary, passed down through generations, forever immemorial in the annals of their history.\n",
      "\n",
      "And so, with her mission accomplished, Eliza bid farewell to Etherealis, knowing that she had made a lasting impact on a realm far beyond her own. With Jasper by her side, she returned to Willowbrook, her heart filled with the memories of the incredible adventure she had undertaken, forever reminding her to embrace curiosity, bravery, and the power of hope.\n",
      "Generated AIConfig Json: \n",
      "('{\\n'\n",
      " '  \"name\": \"\",\\n'\n",
      " '  \"schema_version\": \"latest\",\\n'\n",
      " '  \"metadata\": {\\n'\n",
      " '    \"parameters\": {},\\n'\n",
      " '    \"models\": {}\\n'\n",
      " '  },\\n'\n",
      " '  \"description\": \"\",\\n'\n",
      " '  \"prompts\": [\\n'\n",
      " '    {\\n'\n",
      " '      \"name\": \"prompt_0\",\\n'\n",
      " '      \"input\": \"Hi\",\\n'\n",
      " '      \"metadata\": {\\n'\n",
      " '        \"model\": {\\n'\n",
      " '          \"name\": \"gpt-3.5-turbo\",\\n'\n",
      " '          \"settings\": {\\n'\n",
      " '            \"model\": \"gpt-3.5-turbo\",\\n'\n",
      " '            \"top_p\": 1,\\n'\n",
      " '            \"max_tokens\": 3000,\\n'\n",
      " '            \"temperature\": 1,\\n'\n",
      " '            \"stream\": false\\n'\n",
      " '          }\\n'\n",
      " '        },\\n'\n",
      " '        \"parameters\": {},\\n'\n",
      " '        \"remember_chat_context\": true\\n'\n",
      " '      },\\n'\n",
      " '      \"outputs\": [\\n'\n",
      " '        {\\n'\n",
      " '          \"output_type\": \"execute_result\",\\n'\n",
      " '          \"execution_count\": 0,\\n'\n",
      " '          \"data\": {\\n'\n",
      " '            \"role\": \"assistant\",\\n'\n",
      " '            \"content\": \"Hello! How can I assist you today?\"\\n'\n",
      " '          },\\n'\n",
      " '          \"metadata\": {\\n'\n",
      " '            \"id\": \"chatcmpl-8JbiPv2r26BGtJncNe33UnEyQrxOW\",\\n'\n",
      " '            \"object\": \"chat.completion\",\\n'\n",
      " '            \"created\": 1699683901,\\n'\n",
      " '            \"model\": \"gpt-3.5-turbo-0613\",\\n'\n",
      " '            \"usage\": {\\n'\n",
      " '              \"prompt_tokens\": 8,\\n'\n",
      " '              \"completion_tokens\": 9,\\n'\n",
      " '              \"total_tokens\": 17\\n'\n",
      " '            },\\n'\n",
      " '            \"finish_reason\": \"stop\"\\n'\n",
      " '          }\\n'\n",
      " '        }\\n'\n",
      " '      ]\\n'\n",
      " '    }\\n'\n",
      " '  ]\\n'\n",
      " '}')\n"
     ]
    }
   ],
   "source": [
    "# Set Once and every call will create an AIConfig\n",
    "import openai\n",
    "from aiconfig.ChatCompletion import create_and_save_to_config\n",
    "# Set file path\n",
    "aiconfig_file_path = \"my-second-aiconfig.json\"\n",
    "openai.ChatCompletion.create = create_and_save_to_config(config_file_path=aiconfig_file_path)\n",
    "\n",
    "# Basic Streaming Execution\n",
    "completion_params = {\n",
    "            \"model\": \"gpt-3.5-turbo\",\n",
    "            \"top_p\": 1,\n",
    "            \"max_tokens\": 3000,\n",
    "            \"temperature\": 1,\n",
    "            \"stream\": True,\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"content\": \"Tell me a riveting story\",\n",
    "                    \"role\": \"user\",\n",
    "                }\n",
    "            ],\n",
    "        }\n",
    "\n",
    "response = openai.ChatCompletion.create(**completion_params) # Creates a config saved to aiconfig_file_path = \"my-second-aiconfig.json\"\n",
    "print(\"Chat Completion Streaming Response: \")\n",
    "for iteration in response:\n",
    "    chunk = iteration.get(\"choices\",[{}])[0].get('delta',{}).get('content','')\n",
    "    print(chunk, end = '')\n",
    "\n",
    "\n",
    "print(\"\\nGenerated AIConfig Json: \")\n",
    "pretty_print_file('aiconfig.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated AIConfig Json: \n",
      "('{\\n'\n",
      " '  \"name\": \"\",\\n'\n",
      " '  \"schema_version\": \"latest\",\\n'\n",
      " '  \"metadata\": {\\n'\n",
      " '    \"parameters\": {},\\n'\n",
      " '    \"models\": {}\\n'\n",
      " '  },\\n'\n",
      " '  \"description\": \"\",\\n'\n",
      " '  \"prompts\": [\\n'\n",
      " '    {\\n'\n",
      " '      \"name\": \"prompt_0\",\\n'\n",
      " '      \"input\": \"Tell me a riveting story\",\\n'\n",
      " '      \"metadata\": {\\n'\n",
      " '        \"model\": {\\n'\n",
      " '          \"name\": \"gpt-3.5-turbo\",\\n'\n",
      " '          \"settings\": {\\n'\n",
      " '            \"model\": \"gpt-3.5-turbo\",\\n'\n",
      " '            \"top_p\": 1,\\n'\n",
      " '            \"max_tokens\": 3000,\\n'\n",
      " '            \"temperature\": 1,\\n'\n",
      " '            \"stream\": true\\n'\n",
      " '          }\\n'\n",
      " '        },\\n'\n",
      " '        \"parameters\": {},\\n'\n",
      " '        \"remember_chat_context\": true\\n'\n",
      " '      },\\n'\n",
      " '      \"outputs\": [\\n'\n",
      " '        {\\n'\n",
      " '          \"output_type\": \"execute_result\",\\n'\n",
      " '          \"execution_count\": 0,\\n'\n",
      " '          \"data\": {\\n'\n",
      " '            \"role\": \"assistant\",\\n'\n",
      " '            \"content\": \"Once upon a time, in a small village named Willowbrook, there lived a young girl named Eliza. She was known for her '\n",
      " 'boundless curiosity and adventurous spirit, often spending her days exploring the nearby forest with her loyal companion, a mischievous fox named '\n",
      " 'Jasper.\\\\n\\\\nOne sunny morning, as Eliza set out into the woods, she discovered a hidden path she had never seen before. Filled with excitement, '\n",
      " 'she followed the trail and soon found herself in a clearing unlike anything she had ever seen. In the center stood an ancient-looking tree with '\n",
      " 'pulsating, glowing roots that seemed to emanate a mysterious energy.\\\\n\\\\nDriven by curiosity, Eliza reached out to touch the roots of the '\n",
      " 'enchanted tree. In a whirlwind of shimmering lights, she suddenly found herself transported to a distant land, far away from her familiar '\n",
      " 'village.\\\\n\\\\nIn this new realm, Eliza discovered a breathtaking kingdom known as Etherealis. The kingdom was on the verge of despair, as an evil '\n",
      " 'sorceress named Morgana had cast a dark curse that drained the happiness and hope from its inhabitants. The once-vibrant kingdom now lay in gloom, '\n",
      " 'with the people living in constant fear and sadness.\\\\n\\\\nDetermined to bring back joy to Etherealis, Eliza embarked on a quest to find the fabled '\n",
      " 'Crystal of Dreams, a powerful relic said to possess the ability to restore happiness to the kingdom. Joined by her faithful friend Jasper, Eliza '\n",
      " 'faced perilous challenges, encountered magical creatures, and made new allies along the way.\\\\n\\\\nAs her journey became more treacherous and '\n",
      " \"Morgana's minions grew more formidable, Eliza's courage and determination grew stronger. Through her unwavering spirit, she inspired the people of \"\n",
      " 'Etherealis to rise up and reclaim their kingdom from the clutches of despair.\\\\n\\\\nAfter countless trials and sacrifices, Eliza finally reached '\n",
      " \"the heart of Morgana's lair, where the Crystal of Dreams awaited. With a fierce battle of wits and bravery, Eliza managed to overcome Morgana's \"\n",
      " 'dark powers and shatter the curse that had plagued Etherealis.\\\\n\\\\nAs the curse broke, the land became bathed in a brilliant light, and joy swept '\n",
      " 'through the kingdom like a gentle breeze. The once-despondent villagers emerged from their homes, their faces aglow with renewed hope.\\\\n\\\\nEliza, '\n",
      " 'hailed as the champion of Etherealis, was celebrated by the grateful townspeople. Her name became legendary, passed down through generations, '\n",
      " 'forever immemorial in the annals of their history.\\\\n\\\\nAnd so, with her mission accomplished, Eliza bid farewell to Etherealis, knowing that she '\n",
      " 'had made a lasting impact on a realm far beyond her own. With Jasper by her side, she returned to Willowbrook, her heart filled with the memories '\n",
      " 'of the incredible adventure she had undertaken, forever reminding her to embrace curiosity, bravery, and the power of hope.\"\\n'\n",
      " '          },\\n'\n",
      " '          \"metadata\": {\\n'\n",
      " '            \"finish_reason\": \"stop\"\\n'\n",
      " '          }\\n'\n",
      " '        }\\n'\n",
      " '      ]\\n'\n",
      " '    },\\n'\n",
      " '    {\\n'\n",
      " '      \"name\": \"prompt_1\",\\n'\n",
      " '      \"input\": \"Tell me a joke about apples\",\\n'\n",
      " '      \"metadata\": {\\n'\n",
      " '        \"model\": {\\n'\n",
      " '          \"name\": \"gpt-3.5-turbo\",\\n'\n",
      " '          \"settings\": {\\n'\n",
      " '            \"model\": \"gpt-3.5-turbo\",\\n'\n",
      " '            \"top_p\": 1,\\n'\n",
      " '            \"max_tokens\": 3000,\\n'\n",
      " '            \"temperature\": 1\\n'\n",
      " '          }\\n'\n",
      " '        },\\n'\n",
      " '        \"parameters\": {},\\n'\n",
      " '        \"remember_chat_context\": true\\n'\n",
      " '      },\\n'\n",
      " '      \"outputs\": [\\n'\n",
      " '        {\\n'\n",
      " '          \"output_type\": \"execute_result\",\\n'\n",
      " '          \"data\": {\\n'\n",
      " '            \"role\": \"assistant\",\\n'\n",
      " '            \"content\": \"Why did the apple go to school?\\\\n\\\\nBecause it wanted to be a \\\\\"smarty-pie\\\\\"!\"\\n'\n",
      " '          },\\n'\n",
      " '          \"metadata\": {}\\n'\n",
      " '        }\\n'\n",
      " '      ]\\n'\n",
      " '    },\\n'\n",
      " '    {\\n'\n",
      " '      \"name\": \"prompt_2\",\\n'\n",
      " '      \"input\": \"Tell this joke in a shakespearean rhetoric\",\\n'\n",
      " '      \"metadata\": {\\n'\n",
      " '        \"model\": {\\n'\n",
      " '          \"name\": \"gpt-3.5-turbo\",\\n'\n",
      " '          \"settings\": {\\n'\n",
      " '            \"model\": \"gpt-3.5-turbo\",\\n'\n",
      " '            \"top_p\": 1,\\n'\n",
      " '            \"max_tokens\": 3000,\\n'\n",
      " '            \"temperature\": 1\\n'\n",
      " '          }\\n'\n",
      " '        },\\n'\n",
      " '        \"parameters\": {},\\n'\n",
      " '        \"remember_chat_context\": true\\n'\n",
      " '      },\\n'\n",
      " '      \"outputs\": [\\n'\n",
      " '        {\\n'\n",
      " '          \"output_type\": \"execute_result\",\\n'\n",
      " '          \"execution_count\": 0,\\n'\n",
      " '          \"data\": {\\n'\n",
      " '            \"role\": \"assistant\",\\n'\n",
      " '            \"content\": \"Why did the noble apple venture to the halls of learning?\\\\n\\\\nForsooth, it sought to attain the lofty status of a '\n",
      " '\\\\\"smarty-pie\\\\\"!\"\\n'\n",
      " '          },\\n'\n",
      " '          \"metadata\": {\\n'\n",
      " '            \"id\": \"chatcmpl-8JbibBIOLrajXJXjdcwOMnzeCCFSB\",\\n'\n",
      " '            \"object\": \"chat.completion\",\\n'\n",
      " '            \"created\": 1699683913,\\n'\n",
      " '            \"model\": \"gpt-3.5-turbo-0613\",\\n'\n",
      " '            \"usage\": {\\n'\n",
      " '              \"prompt_tokens\": 50,\\n'\n",
      " '              \"completion_tokens\": 31,\\n'\n",
      " '              \"total_tokens\": 81\\n'\n",
      " '            },\\n'\n",
      " '            \"finish_reason\": \"stop\"\\n'\n",
      " '          }\\n'\n",
      " '        }\\n'\n",
      " '      ]\\n'\n",
      " '    }\\n'\n",
      " '  ]\\n'\n",
      " '}')\n"
     ]
    }
   ],
   "source": [
    "# Set Once and every call will create an AIConfig\n",
    "from aiconfig.Config import AIConfigRuntime\n",
    "import openai\n",
    "from aiconfig.ChatCompletion import create_and_save_to_config\n",
    "# Set aiconfig\n",
    "aiconfig = AIConfigRuntime.load(\"my-second-aiconfig.json\") # load the second aiconfig we just created and use it\n",
    "openai.ChatCompletion.create = create_and_save_to_config(aiconfig=aiconfig)\n",
    "\n",
    "# Compounded Execution\n",
    "completion_params = {\n",
    "            \"model\": \"gpt-3.5-turbo\",\n",
    "            \"top_p\": 1,\n",
    "            \"max_tokens\": 3000,\n",
    "            \"temperature\": 1,\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"content\": \"Tell me a joke about apples\",\n",
    "                    \"role\": \"user\",\n",
    "                }\n",
    "            ],\n",
    "        }\n",
    "\n",
    "response = openai.ChatCompletion.create(**completion_params) # Config was previously loaded from 'my-second-aiconfig.json. New Prompt gets added to the AIConfig Object and also saved to the same file\n",
    "\n",
    "completion_params = {\n",
    "            \"model\": \"gpt-3.5-turbo\",\n",
    "            \"top_p\": 1,\n",
    "            \"max_tokens\": 3000,\n",
    "            \"temperature\": 1,\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"content\": \"Tell me a joke about apples\",\n",
    "                    \"role\": \"user\",\n",
    "                },\n",
    "                 {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"Why did the apple go to school?\\n\\nBecause it wanted to be a \\\"smarty-pie\\\"!\"\n",
    "      },                                \n",
    "      {\n",
    "                    \"content\": \"Tell this joke in a shakespearean rhetoric\",\n",
    "                    \"role\": \"user\",\n",
    "                }\n",
    "            ],\n",
    "        }\n",
    "\n",
    "response = openai.ChatCompletion.create(**completion_params) # Config is updated with the second prompt keeping the history intact\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nGenerated AIConfig Json: \")\n",
    "pretty_print_file('my-second-aiconfig.json') # open the config yourself and check it out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"chatcmpl-8JbierFvvXNJSP0X3uBrs6eKE3gVJ\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1699683916,\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": null,\n",
      "        \"function_call\": {\n",
      "          \"name\": \"get_current_weather\",\n",
      "          \"arguments\": \"{\\n\\\"location\\\": \\\"Boston, MA\\\"\\n}\"\n",
      "        }\n",
      "      },\n",
      "      \"finish_reason\": \"function_call\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 82,\n",
      "    \"completion_tokens\": 17,\n",
      "    \"total_tokens\": 99\n",
      "  }\n",
      "}\n",
      "{\n",
      "  \"id\": \"chatcmpl-8JbienSrramxYu385Tk7RnYwxZGWn\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1699683916,\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"The current weather in Boston is sunny with a temperature of 22 degrees Celsius.\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 134,\n",
      "    \"completion_tokens\": 17,\n",
      "    \"total_tokens\": 151\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Function Call Capture\n",
    "# Set Once and every call will create an AIConfig\n",
    "from aiconfig.Config import AIConfigRuntime\n",
    "import openai\n",
    "from aiconfig.ChatCompletion import create_and_save_to_config\n",
    "# Set aiconfig\n",
    "openai.ChatCompletion.create = create_and_save_to_config(config_file_path='function_call.json')\n",
    "\n",
    "def get_current_weather(location, unit):\n",
    "    return { \"temperature\": 22, \"unit\": \"celsius\", \"description\": \"Sunny\" }\n",
    "\n",
    "completion_params = {\n",
    "    \"model\": \"gpt-3.5-turbo-0613\",\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"What is the weather like in Boston?\"}],\n",
    "    \"functions\": [\n",
    "        {\n",
    "            \"name\": \"get_current_weather\",\n",
    "            \"description\": \"Get the current weather in a given location\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                    },\n",
    "                    \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n",
    "                },\n",
    "                \"required\": [\"location\"],\n",
    "            },\n",
    "        }\n",
    "    ],\n",
    "}\n",
    "\n",
    "response = openai.ChatCompletion.create(**completion_params) \n",
    "\n",
    "function_call_response = get_current_weather(location=\"Boston\", unit=\"celsius\")\n",
    "print(response)\n",
    "\n",
    "completion_params = {\n",
    "  \"model\": \"gpt-3.5-turbo-0613\",\n",
    "  \"messages\": [\n",
    "    {\"role\": \"user\", \"content\": \"What is the weather like in Boston?\"},\n",
    "    {\"role\": \"assistant\", \"content\": 'null', \"function_call\": {\n",
    "          \"name\": \"get_current_weather\",\n",
    "          \"arguments\": \"{\\n  \\\"location\\\": \\\"Boston, MA\\\"\\n}\"\n",
    "        }},\n",
    "    {\"role\": \"function\", \"name\": \"get_current_weather\", \"content\": str(function_call_response)}\n",
    "\n",
    "  ],\n",
    "  \"functions\": [\n",
    "    {\n",
    "      \"name\": \"get_current_weather\",\n",
    "      \"description\": \"Get the current weather in a given location\",\n",
    "      \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "          \"location\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The city and state, e.g. San Francisco, CA\"\n",
    "          },\n",
    "          \"unit\": {\n",
    "            \"type\": \"string\",\n",
    "            \"enum\": [\"celsius\", \"fahrenheit\"]\n",
    "          }\n",
    "        },\n",
    "        \"required\": [\"location\"]\n",
    "      }\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n",
    "response = openai.ChatCompletion.create(**completion_params) \n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
