{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Api Key\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "original_create = openai.chat.completions.create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "\n",
    "def pretty_print_file(file_name):\n",
    "    with open(file_name, 'r') as f:\n",
    "        pp = pprint.PrettyPrinter(indent=4, width = 150)\n",
    "        pp.pprint(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/aiconfig/lib/python3.10/site-packages/pydantic/_internal/_fields.py:149: UserWarning: Field \"model_parsers\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/aiconfig/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat Completion Response: \n",
      "ChatCompletion(id='chatcmpl-8Ph8IjABXSgtka6bxVQ4rYvhXpIcy', choices=[Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Hello! How can I assist you today?', role='assistant', function_call=None, tool_calls=None))], created=1701134694, model='gpt-3.5-turbo-0613', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=9, prompt_tokens=8, total_tokens=17))\n",
      "\n",
      "Generated AIConfig Json: \n",
      "('{\\n'\n",
      " '  \"name\": \"\",\\n'\n",
      " '  \"schema_version\": \"latest\",\\n'\n",
      " '  \"metadata\": {\\n'\n",
      " '    \"parameters\": {},\\n'\n",
      " '    \"models\": {}\\n'\n",
      " '  },\\n'\n",
      " '  \"description\": \"\",\\n'\n",
      " '  \"prompts\": [\\n'\n",
      " '    {\\n'\n",
      " '      \"name\": \"prompt_0\",\\n'\n",
      " '      \"input\": \"Hi\",\\n'\n",
      " '      \"metadata\": {\\n'\n",
      " '        \"model\": {\\n'\n",
      " '          \"name\": \"gpt-3.5-turbo\",\\n'\n",
      " '          \"settings\": {\\n'\n",
      " '            \"model\": \"gpt-3.5-turbo\",\\n'\n",
      " '            \"top_p\": 1,\\n'\n",
      " '            \"max_tokens\": 3000,\\n'\n",
      " '            \"temperature\": 1,\\n'\n",
      " '            \"stream\": false\\n'\n",
      " '          }\\n'\n",
      " '        },\\n'\n",
      " '        \"parameters\": {},\\n'\n",
      " '        \"remember_chat_context\": true\\n'\n",
      " '      },\\n'\n",
      " '      \"outputs\": [\\n'\n",
      " '        {\\n'\n",
      " '          \"output_type\": \"execute_result\",\\n'\n",
      " '          \"execution_count\": 0,\\n'\n",
      " '          \"data\": {\\n'\n",
      " '            \"content\": \"Hello! How can I assist you today?\",\\n'\n",
      " '            \"role\": \"assistant\"\\n'\n",
      " '          },\\n'\n",
      " '          \"metadata\": {\\n'\n",
      " '            \"id\": \"chatcmpl-8Ph8IjABXSgtka6bxVQ4rYvhXpIcy\",\\n'\n",
      " '            \"created\": 1701134694,\\n'\n",
      " '            \"model\": \"gpt-3.5-turbo-0613\",\\n'\n",
      " '            \"object\": \"chat.completion\",\\n'\n",
      " '            \"usage\": {\\n'\n",
      " '              \"completion_tokens\": 9,\\n'\n",
      " '              \"prompt_tokens\": 8,\\n'\n",
      " '              \"total_tokens\": 17\\n'\n",
      " '            },\\n'\n",
      " '            \"finish_reason\": \"stop\"\\n'\n",
      " '          }\\n'\n",
      " '        }\\n'\n",
      " '      ]\\n'\n",
      " '    }\\n'\n",
      " '  ]\\n'\n",
      " '}')\n"
     ]
    }
   ],
   "source": [
    "# Set Once and every call will create an AIConfig\n",
    "import openai\n",
    "from aiconfig.ChatCompletion import create_and_save_to_config\n",
    "openai.chat.completions.create = create_and_save_to_config()\n",
    "\n",
    "# Basic Execution\n",
    "completion_params = {\n",
    "            \"model\": \"gpt-3.5-turbo\",\n",
    "            \"top_p\": 1,\n",
    "            \"max_tokens\": 3000,\n",
    "            \"temperature\": 1,\n",
    "            \"stream\": False,\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"content\": \"Hi\",\n",
    "                    \"role\": \"user\",\n",
    "                }\n",
    "            ],\n",
    "        }\n",
    "\n",
    "response = openai.chat.completions.create(**completion_params) # Creates a config saved to default path `aiconfig.json`\n",
    "print(\"Chat Completion Response: \")\n",
    "pprint.pprint(response)\n",
    "\n",
    "print(\"\\nGenerated AIConfig Json: \")\n",
    "pretty_print_file('aiconfig.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat Completion Streaming Response: \n",
      "Once upon a time, in a small coastal town, there lived a young woman named Emily. She was known for her adventurous spirit and curiosity about the world beyond the sea. One day, a powerful storm was brewing off the shore, and the entire town was in a frenzy preparing for its arrival.\n",
      "\n",
      "While people were securing their homes and taking shelter, Emily couldn't resist the thrill of witnessing the storm firsthand. She grabbed her raincoat, put on her boots, and ventured out towards the beach. As she reached the sandy shores, the wind whipped around her, carrying the salty mist of the incoming waves.\n",
      "\n",
      "Emily's heart raced with excitement as the rain soaked her clothes and the thunder roared overhead. Suddenly, she noticed a peculiar object floating in the turbulent waves. With determination, she waded through the crashing waves, reaching out to grab the mysterious item.\n",
      "\n",
      "To her astonishment, Emily discovered an old, weathered bottle with a beautifully crafted map tucked inside. It was a treasure map, with the promise of hidden riches and long-lost secrets. Unable to contain her curiosity, Emily decided to embark on an adventure to find the treasures marked on the map.\n",
      "\n",
      "Gathering a group of fellow thrill-seekers from the town, Emily set sail on a small sailboat, following the directions on the map. The journey was treacherous, with storms and giant waves testing their resolve at every turn. But they pushed forward, their spirits fueled by the allure of the unknown and the prospect of incredible wealth.\n",
      "\n",
      "Days turned into weeks as the crew ventured deeper into uncharted waters, navigating through treacherous reefs and battling fierce sea creatures. Along the way, they faced numerous challenges, but they persevered, relying on their wits and teamwork.\n",
      "\n",
      "Finally, after months of searching, they reached a deserted island, the final destination according to the map. As they explored the lush jungle, they stumbled upon a hidden cave. Inside, they discovered a trove of ancient artifacts, precious gems, and golden treasures beyond their wildest dreams.\n",
      "\n",
      "Overwhelmed with joy and gratitude, Emily and her crew shared a moment of triumph. But they realized that true treasure lay not in the riches they had found, but in the bonds they had formed and the memories they had created during their extraordinary journey.\n",
      "\n",
      "They returned to their small coastal town as heroes, sharing their story of courage and discovery with the awe-struck townspeople. And from that day forward, the legend of Emily and her adventurous spirit lived on, inspiring generations to follow their dreams and embrace the thrill of the unknown.\n",
      "Generated AIConfig Json: \n",
      "('{\\n'\n",
      " '  \"name\": \"\",\\n'\n",
      " '  \"schema_version\": \"latest\",\\n'\n",
      " '  \"metadata\": {\\n'\n",
      " '    \"parameters\": {},\\n'\n",
      " '    \"models\": {}\\n'\n",
      " '  },\\n'\n",
      " '  \"description\": \"\",\\n'\n",
      " '  \"prompts\": [\\n'\n",
      " '    {\\n'\n",
      " '      \"name\": \"prompt_0\",\\n'\n",
      " '      \"input\": \"Hi\",\\n'\n",
      " '      \"metadata\": {\\n'\n",
      " '        \"model\": {\\n'\n",
      " '          \"name\": \"gpt-3.5-turbo\",\\n'\n",
      " '          \"settings\": {\\n'\n",
      " '            \"model\": \"gpt-3.5-turbo\",\\n'\n",
      " '            \"top_p\": 1,\\n'\n",
      " '            \"max_tokens\": 3000,\\n'\n",
      " '            \"temperature\": 1,\\n'\n",
      " '            \"stream\": false\\n'\n",
      " '          }\\n'\n",
      " '        },\\n'\n",
      " '        \"parameters\": {},\\n'\n",
      " '        \"remember_chat_context\": true\\n'\n",
      " '      },\\n'\n",
      " '      \"outputs\": [\\n'\n",
      " '        {\\n'\n",
      " '          \"output_type\": \"execute_result\",\\n'\n",
      " '          \"execution_count\": 0,\\n'\n",
      " '          \"data\": {\\n'\n",
      " '            \"content\": \"Hello! How can I assist you today?\",\\n'\n",
      " '            \"role\": \"assistant\"\\n'\n",
      " '          },\\n'\n",
      " '          \"metadata\": {\\n'\n",
      " '            \"id\": \"chatcmpl-8Ph8IjABXSgtka6bxVQ4rYvhXpIcy\",\\n'\n",
      " '            \"created\": 1701134694,\\n'\n",
      " '            \"model\": \"gpt-3.5-turbo-0613\",\\n'\n",
      " '            \"object\": \"chat.completion\",\\n'\n",
      " '            \"usage\": {\\n'\n",
      " '              \"completion_tokens\": 9,\\n'\n",
      " '              \"prompt_tokens\": 8,\\n'\n",
      " '              \"total_tokens\": 17\\n'\n",
      " '            },\\n'\n",
      " '            \"finish_reason\": \"stop\"\\n'\n",
      " '          }\\n'\n",
      " '        }\\n'\n",
      " '      ]\\n'\n",
      " '    }\\n'\n",
      " '  ]\\n'\n",
      " '}')\n"
     ]
    }
   ],
   "source": [
    "# Set Once and every call will create an AIConfig\n",
    "import openai\n",
    "from aiconfig.ChatCompletion import create_and_save_to_config\n",
    "# Set file path\n",
    "aiconfig_file_path = \"my-second-aiconfig.json\"\n",
    "openai.chat.completions.create  = create_and_save_to_config(config_file_path=aiconfig_file_path)\n",
    "\n",
    "# Basic Streaming Execution\n",
    "completion_params = {\n",
    "            \"model\": \"gpt-3.5-turbo\",\n",
    "            \"top_p\": 1,\n",
    "            \"max_tokens\": 3000,\n",
    "            \"temperature\": 1,\n",
    "            \"stream\": True,\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"content\": \"Tell me a riveting story\",\n",
    "                    \"role\": \"user\",\n",
    "                }\n",
    "            ],\n",
    "        }\n",
    "\n",
    "response = openai.chat.completions.create(**completion_params) # Creates a config saved to aiconfig_file_path = \"my-second-aiconfig.json\"\n",
    "print(\"Chat Completion Streaming Response: \")\n",
    "for iteration in response:\n",
    "    chunk = iteration.get(\"choices\",[{}])[0].get('delta',{}).get('content','')\n",
    "    print(chunk, end = '')\n",
    "\n",
    "\n",
    "print(\"\\nGenerated AIConfig Json: \")\n",
    "pretty_print_file('aiconfig.json')\n",
    "from openai import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated AIConfig Json: \n",
      "('{\\n'\n",
      " '  \"name\": \"\",\\n'\n",
      " '  \"schema_version\": \"latest\",\\n'\n",
      " '  \"metadata\": {\\n'\n",
      " '    \"parameters\": {},\\n'\n",
      " '    \"models\": {}\\n'\n",
      " '  },\\n'\n",
      " '  \"description\": \"\",\\n'\n",
      " '  \"prompts\": [\\n'\n",
      " '    {\\n'\n",
      " '      \"name\": \"prompt_0\",\\n'\n",
      " '      \"input\": \"Tell me a riveting story\",\\n'\n",
      " '      \"metadata\": {\\n'\n",
      " '        \"model\": {\\n'\n",
      " '          \"name\": \"gpt-3.5-turbo\",\\n'\n",
      " '          \"settings\": {\\n'\n",
      " '            \"model\": \"gpt-3.5-turbo\",\\n'\n",
      " '            \"top_p\": 1,\\n'\n",
      " '            \"max_tokens\": 3000,\\n'\n",
      " '            \"temperature\": 1,\\n'\n",
      " '            \"stream\": true\\n'\n",
      " '          }\\n'\n",
      " '        },\\n'\n",
      " '        \"parameters\": {},\\n'\n",
      " '        \"remember_chat_context\": true\\n'\n",
      " '      },\\n'\n",
      " '      \"outputs\": [\\n'\n",
      " '        {\\n'\n",
      " '          \"output_type\": \"execute_result\",\\n'\n",
      " '          \"execution_count\": 0,\\n'\n",
      " '          \"data\": {\\n'\n",
      " '            \"content\": \"Once upon a time, in a small coastal town, there lived a young woman named Emily. She was known for her adventurous spirit '\n",
      " 'and curiosity about the world beyond the sea. One day, a powerful storm was brewing off the shore, and the entire town was in a frenzy preparing '\n",
      " \"for its arrival.\\\\n\\\\nWhile people were securing their homes and taking shelter, Emily couldn't resist the thrill of witnessing the storm \"\n",
      " 'firsthand. She grabbed her raincoat, put on her boots, and ventured out towards the beach. As she reached the sandy shores, the wind whipped '\n",
      " \"around her, carrying the salty mist of the incoming waves.\\\\n\\\\nEmily's heart raced with excitement as the rain soaked her clothes and the thunder \"\n",
      " 'roared overhead. Suddenly, she noticed a peculiar object floating in the turbulent waves. With determination, she waded through the crashing '\n",
      " 'waves, reaching out to grab the mysterious item.\\\\n\\\\nTo her astonishment, Emily discovered an old, weathered bottle with a beautifully crafted '\n",
      " 'map tucked inside. It was a treasure map, with the promise of hidden riches and long-lost secrets. Unable to contain her curiosity, Emily decided '\n",
      " 'to embark on an adventure to find the treasures marked on the map.\\\\n\\\\nGathering a group of fellow thrill-seekers from the town, Emily set sail '\n",
      " 'on a small sailboat, following the directions on the map. The journey was treacherous, with storms and giant waves testing their resolve at every '\n",
      " 'turn. But they pushed forward, their spirits fueled by the allure of the unknown and the prospect of incredible wealth.\\\\n\\\\nDays turned into '\n",
      " 'weeks as the crew ventured deeper into uncharted waters, navigating through treacherous reefs and battling fierce sea creatures. Along the way, '\n",
      " 'they faced numerous challenges, but they persevered, relying on their wits and teamwork.\\\\n\\\\nFinally, after months of searching, they reached a '\n",
      " 'deserted island, the final destination according to the map. As they explored the lush jungle, they stumbled upon a hidden cave. Inside, they '\n",
      " 'discovered a trove of ancient artifacts, precious gems, and golden treasures beyond their wildest dreams.\\\\n\\\\nOverwhelmed with joy and gratitude, '\n",
      " 'Emily and her crew shared a moment of triumph. But they realized that true treasure lay not in the riches they had found, but in the bonds they '\n",
      " 'had formed and the memories they had created during their extraordinary journey.\\\\n\\\\nThey returned to their small coastal town as heroes, sharing '\n",
      " 'their story of courage and discovery with the awe-struck townspeople. And from that day forward, the legend of Emily and her adventurous spirit '\n",
      " 'lived on, inspiring generations to follow their dreams and embrace the thrill of the unknown.\",\\n'\n",
      " '            \"role\": \"assistant\"\\n'\n",
      " '          },\\n'\n",
      " '          \"metadata\": {\\n'\n",
      " '            \"finish_reason\": \"stop\"\\n'\n",
      " '          }\\n'\n",
      " '        }\\n'\n",
      " '      ]\\n'\n",
      " '    },\\n'\n",
      " '    {\\n'\n",
      " '      \"name\": \"prompt_1\",\\n'\n",
      " '      \"input\": \"Tell me a joke about apples\",\\n'\n",
      " '      \"metadata\": {\\n'\n",
      " '        \"model\": {\\n'\n",
      " '          \"name\": \"gpt-3.5-turbo\",\\n'\n",
      " '          \"settings\": {\\n'\n",
      " '            \"model\": \"gpt-3.5-turbo\",\\n'\n",
      " '            \"top_p\": 1,\\n'\n",
      " '            \"max_tokens\": 3000,\\n'\n",
      " '            \"temperature\": 1\\n'\n",
      " '          }\\n'\n",
      " '        },\\n'\n",
      " '        \"parameters\": {},\\n'\n",
      " '        \"remember_chat_context\": true\\n'\n",
      " '      },\\n'\n",
      " '      \"outputs\": [\\n'\n",
      " '        {\\n'\n",
      " '          \"output_type\": \"execute_result\",\\n'\n",
      " '          \"data\": {\\n'\n",
      " '            \"role\": \"assistant\",\\n'\n",
      " '            \"content\": \"Why did the apple go to school?\\\\n\\\\nBecause it wanted to be a \\\\\"smarty-pie\\\\\"!\"\\n'\n",
      " '          },\\n'\n",
      " '          \"metadata\": {}\\n'\n",
      " '        }\\n'\n",
      " '      ]\\n'\n",
      " '    },\\n'\n",
      " '    {\\n'\n",
      " '      \"name\": \"prompt_2\",\\n'\n",
      " '      \"input\": \"Tell this joke in a shakespearean rhetoric\",\\n'\n",
      " '      \"metadata\": {\\n'\n",
      " '        \"model\": {\\n'\n",
      " '          \"name\": \"gpt-3.5-turbo\",\\n'\n",
      " '          \"settings\": {\\n'\n",
      " '            \"model\": \"gpt-3.5-turbo\",\\n'\n",
      " '            \"top_p\": 1,\\n'\n",
      " '            \"max_tokens\": 3000,\\n'\n",
      " '            \"temperature\": 1\\n'\n",
      " '          }\\n'\n",
      " '        },\\n'\n",
      " '        \"parameters\": {},\\n'\n",
      " '        \"remember_chat_context\": true\\n'\n",
      " '      },\\n'\n",
      " '      \"outputs\": [\\n'\n",
      " '        {\\n'\n",
      " '          \"output_type\": \"execute_result\",\\n'\n",
      " '          \"execution_count\": 0,\\n'\n",
      " '          \"data\": {\\n'\n",
      " '            \"content\": \"Why did the noble apple seeketh education at the hallowed halls of academe?\\\\n\\\\nForsooth, it aspireth to attain the '\n",
      " 'status of a \\\\\"smarty-pie\\\\\"!\",\\n'\n",
      " '            \"role\": \"assistant\"\\n'\n",
      " '          },\\n'\n",
      " '          \"metadata\": {\\n'\n",
      " '            \"id\": \"chatcmpl-8Ph8Wg76BZoJu0FjedoGdqd73eKw5\",\\n'\n",
      " '            \"created\": 1701134708,\\n'\n",
      " '            \"model\": \"gpt-3.5-turbo-0613\",\\n'\n",
      " '            \"object\": \"chat.completion\",\\n'\n",
      " '            \"usage\": {\\n'\n",
      " '              \"completion_tokens\": 36,\\n'\n",
      " '              \"prompt_tokens\": 50,\\n'\n",
      " '              \"total_tokens\": 86\\n'\n",
      " '            },\\n'\n",
      " '            \"finish_reason\": \"stop\"\\n'\n",
      " '          }\\n'\n",
      " '        }\\n'\n",
      " '      ]\\n'\n",
      " '    }\\n'\n",
      " '  ]\\n'\n",
      " '}')\n"
     ]
    }
   ],
   "source": [
    "# Set Once and every call will create an AIConfig\n",
    "from aiconfig.Config import AIConfigRuntime\n",
    "import openai\n",
    "from aiconfig.ChatCompletion import create_and_save_to_config\n",
    "# Set aiconfig\n",
    "aiconfig = AIConfigRuntime.load(\"my-second-aiconfig.json\") # load the second aiconfig we just created and use it\n",
    "openai.chat.completions.create = create_and_save_to_config(aiconfig=aiconfig)\n",
    "\n",
    "# Compounded Execution\n",
    "completion_params = {\n",
    "            \"model\": \"gpt-3.5-turbo\",\n",
    "            \"top_p\": 1,\n",
    "            \"max_tokens\": 3000,\n",
    "            \"temperature\": 1,\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"content\": \"Tell me a joke about apples\",\n",
    "                    \"role\": \"user\",\n",
    "                }\n",
    "            ],\n",
    "        }\n",
    "\n",
    "response = openai.chat.completions.create(**completion_params) # Config was previously loaded from 'my-second-aiconfig.json. New Prompt gets added to the AIConfig Object and also saved to the same file\n",
    "\n",
    "completion_params = {\n",
    "            \"model\": \"gpt-3.5-turbo\",\n",
    "            \"top_p\": 1,\n",
    "            \"max_tokens\": 3000,\n",
    "            \"temperature\": 1,\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"content\": \"Tell me a joke about apples\",\n",
    "                    \"role\": \"user\",\n",
    "                },\n",
    "                 {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"Why did the apple go to school?\\n\\nBecause it wanted to be a \\\"smarty-pie\\\"!\"\n",
    "      },                                \n",
    "      {\n",
    "                    \"content\": \"Tell this joke in a shakespearean rhetoric\",\n",
    "                    \"role\": \"user\",\n",
    "                }\n",
    "            ],\n",
    "        }\n",
    "\n",
    "response = openai.chat.completions.create(**completion_params) # Config is updated with the second prompt keeping the history intact\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nGenerated AIConfig Json: \")\n",
    "pretty_print_file('my-second-aiconfig.json') # open the config yourself and check it out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-8Ph8XOw6LIF4pPNdFLMkBvtdn5cgG', choices=[Choice(finish_reason='function_call', index=0, message=ChatCompletionMessage(content=None, role='assistant', function_call=FunctionCall(arguments='{\\n  \"location\": \"Boston, MA\"\\n}', name='get_current_weather'), tool_calls=None))], created=1701134709, model='gpt-3.5-turbo-0613', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=18, prompt_tokens=82, total_tokens=100))\n",
      "ChatCompletion(id='chatcmpl-8Ph8YZd33EJI1YrDqnmdjG3ZyAkse', choices=[Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='The current weather in Boston is sunny with a temperature of 22 degrees Celsius.', role='assistant', function_call=None, tool_calls=None))], created=1701134710, model='gpt-3.5-turbo-0613', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=17, prompt_tokens=134, total_tokens=151))\n"
     ]
    }
   ],
   "source": [
    "# Function Call Capture\n",
    "# Set Once and every call will create an AIConfig\n",
    "from aiconfig.Config import AIConfigRuntime\n",
    "import openai\n",
    "from aiconfig.ChatCompletion import create_and_save_to_config\n",
    "# Set aiconfig\n",
    "openai.chat.completions.create = create_and_save_to_config(config_file_path='function_call.json')\n",
    "\n",
    "def get_current_weather(location, unit):\n",
    "    return { \"temperature\": 22, \"unit\": \"celsius\", \"description\": \"Sunny\" }\n",
    "\n",
    "completion_params = {\n",
    "    \"model\": \"gpt-3.5-turbo-0613\",\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"What is the weather like in Boston?\"}],\n",
    "    \"functions\": [\n",
    "        {\n",
    "            \"name\": \"get_current_weather\",\n",
    "            \"description\": \"Get the current weather in a given location\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                    },\n",
    "                    \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n",
    "                },\n",
    "                \"required\": [\"location\"],\n",
    "            },\n",
    "        }\n",
    "    ],\n",
    "}\n",
    "\n",
    "response = openai.chat.completions.create(**completion_params) \n",
    "\n",
    "function_call_response = get_current_weather(location=\"Boston\", unit=\"celsius\")\n",
    "print(response)\n",
    "\n",
    "completion_params = {\n",
    "  \"model\": \"gpt-3.5-turbo-0613\",\n",
    "  \"messages\": [\n",
    "    {\"role\": \"user\", \"content\": \"What is the weather like in Boston?\"},\n",
    "    {\"role\": \"assistant\", \"content\": 'null', \"function_call\": {\n",
    "          \"name\": \"get_current_weather\",\n",
    "          \"arguments\": \"{\\n  \\\"location\\\": \\\"Boston, MA\\\"\\n}\"\n",
    "        }},\n",
    "    {\"role\": \"function\", \"name\": \"get_current_weather\", \"content\": str(function_call_response)}\n",
    "\n",
    "  ],\n",
    "  \"functions\": [\n",
    "    {\n",
    "      \"name\": \"get_current_weather\",\n",
    "      \"description\": \"Get the current weather in a given location\",\n",
    "      \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "          \"location\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The city and state, e.g. San Francisco, CA\"\n",
    "          },\n",
    "          \"unit\": {\n",
    "            \"type\": \"string\",\n",
    "            \"enum\": [\"celsius\", \"fahrenheit\"]\n",
    "          }\n",
    "        },\n",
    "        \"required\": [\"location\"]\n",
    "      }\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n",
    "response = openai.chat.completions.create(**completion_params) \n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "# Instantiate a client\n",
    "from aiconfig.ChatCompletion import create_and_save_to_config\n",
    "\n",
    "client = openai.Client()\n",
    "client.chat.completions.create = create_and_save_to_config()\n",
    "\n",
    "completion_params = {\n",
    "            \"model\": \"gpt-3.5-turbo\",\n",
    "            \"top_p\": 1,\n",
    "            \"max_tokens\": 3000,\n",
    "            \"temperature\": 1,\n",
    "            \"stream\": False,\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"content\": \"Hi 2\",\n",
    "                    \"role\": \"user\",\n",
    "                }\n",
    "            ],\n",
    "        }\n",
    "response = client.chat.completions.create(**completion_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(response)=<class 'dict'>, response={'id': 'chatcmpl-8Ph8alhr9393KhKCxI1pAs5khYfHl', 'choices': [{'finish_reason': 'stop', 'index': 0, 'message': {'content': 'I\\'m sorry, I don\\'t understand what you mean by \"Hi 2.\" Can you please provide more context or let me know how I can help you?', 'role': 'assistant'}}], 'created': 1701134712, 'model': 'gpt-3.5-turbo-0613', 'object': 'chat.completion', 'usage': {'completion_tokens': 33, 'prompt_tokens': 23, 'total_tokens': 56}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[ExecuteResult(output_type='execute_result', execution_count=0, data={'content': 'I\\'m sorry, I don\\'t understand what you mean by \"Hi 2.\" Can you please provide more context or let me know how I can help you?', 'role': 'assistant'}, mime_type=None, metadata={'id': 'chatcmpl-8Ph8alhr9393KhKCxI1pAs5khYfHl', 'created': 1701134712, 'model': 'gpt-3.5-turbo-0613', 'object': 'chat.completion', 'usage': {'completion_tokens': 33, 'prompt_tokens': 23, 'total_tokens': 56}, 'finish_reason': 'stop'})]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from aiconfig import AIConfigRuntime\n",
    "from aiconfig import InferenceOptions\n",
    "import openai\n",
    "\n",
    "config = AIConfigRuntime.load(\"aiconfig.json\")\n",
    "inference_options = InferenceOptions(stream=False)\n",
    "await config.run(\"prompt_0\", options = inference_options)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
