{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Promptfoo-style eval without promptfoo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal: Run test-suite-style eval (like Promptfoo) with completely custom components, i.e. without using Promptfoo.\n",
    "\n",
    "In this case, you have 2 options:\n",
    "1. Run with inputs. Library runs AIConfig for you first.\n",
    "2. Run with outputs only. You run AIConfig and save the outputs for eval.\n",
    "\n",
    "Run the notebook in order for an example of each.\n",
    "\n",
    "Assumptions:\n",
    "* You have a parametrized AIConfig with a test input called \"the_query\", like this: \n",
    "`\"input\": \"{{the_query}}\"`\n",
    "* You have some evaluation criteria in mind for the AIConfig's text output.\n",
    "* Promptfoo integration does not meet my needs, e.g.\n",
    "  * You want to run the AIConfig myself instead of handing control to Promptfoo\n",
    "  * You need to scale beyond what Promptfoo can reasonably handle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lastmile-utils               0.0.9\n"
     ]
    }
   ],
   "source": [
    "# Package installs & environment setup\n",
    "!pip3 install lastmile-utils --force\n",
    "# If you see errors, no worries you can generally ignore. Just make sure that the \n",
    "# following output matches with the version specified in the \n",
    "# aiconfig/python/requirements.txt file (or is a higher version)\n",
    "!pip3 list | grep lastmile-utils\n",
    "\n",
    "import openai\n",
    "\n",
    "# Create ~/.env file with this line: `export OPENAI_API_KEY=<your key here>`\n",
    "# You can get your key from https://platform.openai.com/api-keys \n",
    "import dotenv\n",
    "import os\n",
    "dotenv.load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports and set log level\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/pydantic/_internal/_fields.py:128: UserWarning: Field \"model_parsers\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "print(\"Imports and set log level\")\n",
    "\n",
    "import logging\n",
    "\n",
    "import pandas as pd\n",
    "import lastmile_utils.lib.jupyter as jupyter_utils\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "\n",
    "from aiconfig.eval.api import (\n",
    "    brevity,\n",
    "    substring_match,\n",
    "    run_test_suite_with_inputs,\n",
    "    TestSuiteWithInputsSettings,\n",
    ")\n",
    "\n",
    "jupyter_utils.set_log_level(logging.WARNING)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 1: provide inputs, library runs AIConfig for you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Define test suite with inputs (option 1), \n",
      "      as opposed to using pre-computed AIConfig outputs (option 2)\n",
      "      \n",
      "      Define list of inputs and test criteria.\n",
      "      In this case, we are checking brevity for each test case\n",
      "      as well as checking that each output contains a specific expected substring.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"\"\"\n",
    "    Define test suite with inputs (option 1), \n",
    "      as opposed to using pre-computed AIConfig outputs (option 2)\n",
    "      \n",
    "      Define list of inputs and test criteria.\n",
    "      In this case, we are checking brevity for each test case\n",
    "      as well as checking that each output contains a specific expected substring.\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "ts_settings = TestSuiteWithInputsSettings(\n",
    "    prompt_name=\"gen_itinerary\",\n",
    "    aiconfig_path=\"./travel_parametrized.aiconfig.json\",\n",
    ")\n",
    "\n",
    "# Each of these pairs will be used to construct a test case just below.\n",
    "# For each pair (input, expected_substring) we define a test case that says, \n",
    "# \"When I run this input through this AIConfig, \n",
    "# I expect the output to contain this particular substring\".\n",
    "\n",
    "# For example, when we call `substring_match(substring, case_sensitive=False)` below,\n",
    "# and substring==\"Empire State Building\", we are telling the library to create a \n",
    "# boolean metric (i.e. a pass/fail test case) that passes (value==1.0) if the substring\n",
    "# \"empire state building\" appears in the AIConfig output \n",
    "# when the AIConfig is given the input \"Iconic midtown skyscrapers\".\n",
    "# \"Tell me 3 fun attractions related to {{the_query}} to do in NYC.\"\n",
    "# Each test input will get put into \"the_query\" in the input prompt:\n",
    "# See the aiconfig (python/src/aiconfig/eval/custom_eval/examples/travel/travel_parametrized.aiconfig.json).\n",
    "test_inputs_with_substrings = [\n",
    "    (\"different kinds of cuisines\", \"Magnolia Bakery\"),\n",
    "    (\"iconic midtown skyscrapers\", \"Empire State Building\"),\n",
    "]\n",
    "expected_substrings = []\n",
    "\n",
    "test_suite_with_inputs = []\n",
    "for test_input, substring in test_inputs_with_substrings:\n",
    "    # Add the brevity metric\n",
    "    test_fn1 = brevity\n",
    "    test_suite_with_inputs.append((test_input, test_fn1))\n",
    "    # Add substring check function\n",
    "    test_fn2 = substring_match(substring, case_sensitive=False)\n",
    "    test_suite_with_inputs.append((test_input, test_fn2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If you like, you can inspect the test suite before passing it to the evaluation library.\n",
      "\n",
      "Test input:\n",
      " different kinds of cuisines \n",
      "Function:\n",
      " Metric(calculate=<function _calculate_brevity at 0x15133f240>, interpretation={\n",
      "  \"name\": \"brevity\",\n",
      "  \"description\": \"Absolute text length\",\n",
      "  \"best_value\": 1.0,\n",
      "  \"worst_value\": Infinity,\n",
      "  \"extra_metadata\": {}\n",
      "})\n",
      "\n",
      "Test input:\n",
      " different kinds of cuisines \n",
      "Function:\n",
      " Metric(calculate=<function substring_match.<locals>._fn at 0x16a140e00>, interpretation={\n",
      "  \"name\": \"substring_match\",\n",
      "  \"description\": \"1.0 (pass) if contains given substring\",\n",
      "  \"best_value\": 1.0,\n",
      "  \"worst_value\": 0.0,\n",
      "  \"extra_metadata\": {\n",
      "    \"substring\": \"Magnolia Bakery\",\n",
      "    \"case_sensitive\": false\n",
      "  }\n",
      "})\n",
      "\n",
      "Test input:\n",
      " iconic midtown skyscrapers \n",
      "Function:\n",
      " Metric(calculate=<function _calculate_brevity at 0x15133f240>, interpretation={\n",
      "  \"name\": \"brevity\",\n",
      "  \"description\": \"Absolute text length\",\n",
      "  \"best_value\": 1.0,\n",
      "  \"worst_value\": Infinity,\n",
      "  \"extra_metadata\": {}\n",
      "})\n",
      "\n",
      "Test input:\n",
      " iconic midtown skyscrapers \n",
      "Function:\n",
      " Metric(calculate=<function substring_match.<locals>._fn at 0x16a1411c0>, interpretation={\n",
      "  \"name\": \"substring_match\",\n",
      "  \"description\": \"1.0 (pass) if contains given substring\",\n",
      "  \"best_value\": 1.0,\n",
      "  \"worst_value\": 0.0,\n",
      "  \"extra_metadata\": {\n",
      "    \"substring\": \"Empire State Building\",\n",
      "    \"case_sensitive\": false\n",
      "  }\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(\"If you like, you can inspect the test suite before passing it to the evaluation library.\")\n",
    "\n",
    "for test_input, fn in test_suite_with_inputs:\n",
    "    print(\"\\nTest input:\\n\", test_input, \"\\nFunction:\\n\", fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lastmile-utils               0.0.9\n"
     ]
    }
   ],
   "source": [
    "!pip list | grep lastmile-utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run the eval interface (option 1, with inputs)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'lastmile_utils.lib.core.api' has no attribute 'hash_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/rossdancraig/Projects/aiconfig/python/src/aiconfig/eval/examples/travel/travel_eval.ipynb Cell 8\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/rossdancraig/Projects/aiconfig/python/src/aiconfig/eval/examples/travel/travel_eval.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mRun the eval interface (option 1, with inputs)\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/rossdancraig/Projects/aiconfig/python/src/aiconfig/eval/examples/travel/travel_eval.ipynb#W6sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m df_result \u001b[39m=\u001b[39m \u001b[39mawait\u001b[39;00m run_test_suite_with_inputs(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/rossdancraig/Projects/aiconfig/python/src/aiconfig/eval/examples/travel/travel_eval.ipynb#W6sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     test_suite\u001b[39m=\u001b[39mtest_suite_with_inputs,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/rossdancraig/Projects/aiconfig/python/src/aiconfig/eval/examples/travel/travel_eval.ipynb#W6sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     settings\u001b[39m=\u001b[39mts_settings,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/rossdancraig/Projects/aiconfig/python/src/aiconfig/eval/examples/travel/travel_eval.ipynb#W6sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m )\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/rossdancraig/Projects/aiconfig/python/src/aiconfig/eval/examples/travel/travel_eval.ipynb#W6sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mRaw output\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/rossdancraig/Projects/aiconfig/python/src/aiconfig/eval/examples/travel/travel_eval.ipynb#W6sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m df_result\n",
      "File \u001b[0;32m~/Projects/aiconfig/python/src/aiconfig/eval/lib.py:38\u001b[0m, in \u001b[0;36mrun_test_suite_with_inputs\u001b[0;34m(test_suite, settings)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mdef\u001b[39;00m \u001b[39mrun_test_suite_with_inputs\u001b[39m(\n\u001b[1;32m     34\u001b[0m     test_suite: UserTestSuiteWithInputs,\n\u001b[1;32m     35\u001b[0m     settings: TestSuiteWithInputsSettings,\n\u001b[1;32m     36\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m pd\u001b[39m.\u001b[39mDataFrame:\n\u001b[1;32m     37\u001b[0m     aiconfig \u001b[39m=\u001b[39m AIConfigRuntime\u001b[39m.\u001b[39mload(settings\u001b[39m.\u001b[39maiconfig_path)  \u001b[39m# type: ignore[fixme, no-untyped-call]\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m     res \u001b[39m=\u001b[39m \u001b[39mawait\u001b[39;00m run_test_suite_helper(\n\u001b[1;32m     39\u001b[0m         TestSuiteWithInputsSpec(\n\u001b[1;32m     40\u001b[0m             test_suite\u001b[39m=\u001b[39mtest_suite,\n\u001b[1;32m     41\u001b[0m             prompt_name\u001b[39m=\u001b[39msettings\u001b[39m.\u001b[39mprompt_name,\n\u001b[1;32m     42\u001b[0m             aiconfig\u001b[39m=\u001b[39maiconfig,\n\u001b[1;32m     43\u001b[0m         )\n\u001b[1;32m     44\u001b[0m     )\n\u001b[1;32m     45\u001b[0m     \u001b[39mreturn\u001b[39;00m res\u001b[39m.\u001b[39munwrap_or_raise(\u001b[39mValueError\u001b[39;00m)\n",
      "File \u001b[0;32m~/Projects/aiconfig/python/src/aiconfig/eval/lib.py:251\u001b[0m, in \u001b[0;36mrun_test_suite_helper\u001b[0;34m(test_suite_spec)\u001b[0m\n\u001b[1;32m    248\u001b[0m             \u001b[39mreturn\u001b[39;00m Ok(user_test_suite_outputs_only_to_eval_params_list(test_suite))\n\u001b[1;32m    250\u001b[0m eval_params_list \u001b[39m=\u001b[39m \u001b[39mawait\u001b[39;00m _get_eval_params_list(test_suite_spec)\n\u001b[0;32m--> 251\u001b[0m \u001b[39mreturn\u001b[39;00m eval_params_list\u001b[39m.\u001b[39;49mand_then(evaluate)\u001b[39m.\u001b[39;49mmap(eval_res_to_df)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/result/result.py:146\u001b[0m, in \u001b[0;36mOk.map\u001b[0;34m(self, op)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmap\u001b[39m(\u001b[39mself\u001b[39m, op: Callable[[T], U]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Ok[U]:\n\u001b[1;32m    142\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[39m    The contained result is `Ok`, so return `Ok` with original value mapped to\u001b[39;00m\n\u001b[1;32m    144\u001b[0m \u001b[39m    a new value using the passed in function.\u001b[39;00m\n\u001b[1;32m    145\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 146\u001b[0m     \u001b[39mreturn\u001b[39;00m Ok(op(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_value))\n",
      "File \u001b[0;32m~/Projects/aiconfig/python/src/aiconfig/eval/lib.py:130\u001b[0m, in \u001b[0;36meval_res_to_df\u001b[0;34m(eval_res)\u001b[0m\n\u001b[1;32m    123\u001b[0m records: \u001b[39mlist\u001b[39m[\u001b[39mdict\u001b[39m[\u001b[39mstr\u001b[39m, \u001b[39mNone\u001b[39;00m \u001b[39m|\u001b[39m \u001b[39mstr\u001b[39m \u001b[39m|\u001b[39m \u001b[39mfloat\u001b[39m \u001b[39m|\u001b[39m T_InputDatum \u001b[39m|\u001b[39m T_OutputDatum]] \u001b[39m=\u001b[39m []\n\u001b[1;32m    124\u001b[0m \u001b[39mfor\u001b[39;00m sample_res \u001b[39min\u001b[39;00m eval_res:\n\u001b[1;32m    125\u001b[0m     records\u001b[39m.\u001b[39mappend(\n\u001b[1;32m    126\u001b[0m         \u001b[39mdict\u001b[39m(\n\u001b[1;32m    127\u001b[0m             \u001b[39minput\u001b[39m\u001b[39m=\u001b[39msample_res\u001b[39m.\u001b[39minput_datum,\n\u001b[1;32m    128\u001b[0m             aiconfig_output\u001b[39m=\u001b[39msample_res\u001b[39m.\u001b[39moutput_datum,\n\u001b[1;32m    129\u001b[0m             value\u001b[39m=\u001b[39msample_res\u001b[39m.\u001b[39mmetric_value\u001b[39m.\u001b[39mvalue,\n\u001b[0;32m--> 130\u001b[0m             metric_id\u001b[39m=\u001b[39msample_res\u001b[39m.\u001b[39;49mmetric_value\u001b[39m.\u001b[39;49minterpretation\u001b[39m.\u001b[39;49mid,\n\u001b[1;32m    131\u001b[0m             metric_name\u001b[39m=\u001b[39msample_res\u001b[39m.\u001b[39mmetric_value\u001b[39m.\u001b[39minterpretation\u001b[39m.\u001b[39mname,\n\u001b[1;32m    132\u001b[0m             metric_description\u001b[39m=\u001b[39msample_res\u001b[39m.\u001b[39mmetric_value\u001b[39m.\u001b[39minterpretation\u001b[39m.\u001b[39mdescription,\n\u001b[1;32m    133\u001b[0m             best_possible_value\u001b[39m=\u001b[39msample_res\u001b[39m.\u001b[39mmetric_value\u001b[39m.\u001b[39minterpretation\u001b[39m.\u001b[39mbest_value,\n\u001b[1;32m    134\u001b[0m             worst_possible_value\u001b[39m=\u001b[39msample_res\u001b[39m.\u001b[39mmetric_value\u001b[39m.\u001b[39minterpretation\u001b[39m.\u001b[39mworst_value,\n\u001b[1;32m    135\u001b[0m         )\n\u001b[1;32m    136\u001b[0m     )\n\u001b[1;32m    137\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame\u001b[39m.\u001b[39mfrom_records(records)  \u001b[39m# type: ignore[no-untyped-call]\u001b[39;00m\n\u001b[1;32m    138\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(df) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pydantic/main.py:756\u001b[0m, in \u001b[0;36mBaseModel.__getattr__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    754\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    755\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m, item):\n\u001b[0;32m--> 756\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__getattribute__\u001b[39;49m(item)  \u001b[39m# Raises AttributeError if appropriate\u001b[39;00m\n\u001b[1;32m    757\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    758\u001b[0m         \u001b[39m# this is the current error\u001b[39;00m\n\u001b[1;32m    759\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m!r}\u001b[39;00m\u001b[39m object has no attribute \u001b[39m\u001b[39m{\u001b[39;00mitem\u001b[39m!r}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/Projects/aiconfig/python/src/aiconfig/eval/common.py:85\u001b[0m, in \u001b[0;36mEvaluationMetricMetadata.id\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[1;32m     84\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mid\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[0;32m---> 85\u001b[0m     \u001b[39mreturn\u001b[39;00m cu\u001b[39m.\u001b[39;49mhash_id(\n\u001b[1;32m     86\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdescription\u001b[39m}\u001b[39;00m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbest_value\u001b[39m}\u001b[39;00m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mworst_value\u001b[39m}\u001b[39;00m\u001b[39mparams=\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_serialize_extra_metadata()\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mencode(\n\u001b[1;32m     87\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     88\u001b[0m         )\n\u001b[1;32m     89\u001b[0m     )\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'lastmile_utils.lib.core.api' has no attribute 'hash_id'"
     ]
    }
   ],
   "source": [
    "print(\"Run the eval interface (option 1, with inputs)\")\n",
    "\n",
    "df_result = await run_test_suite_with_inputs(\n",
    "    test_suite=test_suite_with_inputs,\n",
    "    settings=ts_settings,\n",
    ")\n",
    "\n",
    "print(\"Raw output\")\n",
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unstack for nicer manual review\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric_name</th>\n",
       "      <th>brevity</th>\n",
       "      <th>substring_match</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>input</th>\n",
       "      <th>aiconfig_output</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>different kinds of cuisines</th>\n",
       "      <th>Visit Chelsea Market for diverse cuisine. Join Chinatown Food Tour for Chinese dishes. Explore Little Italy on a culinary walking tour.</th>\n",
       "      <td>135.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iconic midtown skyscrapers</th>\n",
       "      <th>1. Top of the Rock\\n2. Empire State Building\\n3. NBC Studio Tour</th>\n",
       "      <td>62.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "metric_name                                                                                                                                                          brevity  \\\n",
       "input                       aiconfig_output                                                                                                                                    \n",
       "different kinds of cuisines Visit Chelsea Market for diverse cuisine. Join Chinatown Food Tour for Chinese dishes. Explore Little Italy on a culinary walking tour.    135.0   \n",
       "iconic midtown skyscrapers  1. Top of the Rock\\n2. Empire State Building\\n3. NBC Studio Tour                                                                            62.0   \n",
       "\n",
       "metric_name                                                                                                                                                          substring_match  \n",
       "input                       aiconfig_output                                                                                                                                           \n",
       "different kinds of cuisines Visit Chelsea Market for diverse cuisine. Join Chinatown Food Tour for Chinese dishes. Explore Little Italy on a culinary walking tour.              0.0  \n",
       "iconic midtown skyscrapers  1. Top of the Rock\\n2. Empire State Building\\n3. NBC Studio Tour                                                                                     1.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Unstack for nicer manual review\")\n",
    "df_result.set_index([\"input\", \"aiconfig_output\", \"metric_name\"])\\\n",
    "        .value.unstack(\"metric_name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 2: Run eval on already-computed AIConfig outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Define outputs to test and criteria, similar to option 1.\n"
     ]
    }
   ],
   "source": [
    "print(\"Define outputs to test and criteria, similar to option 1.\")\n",
    "\n",
    "\n",
    "from aiconfig.eval.api import (\n",
    "    brevity,\n",
    "    substring_match,\n",
    "    run_test_suite_outputs_only,\n",
    ")\n",
    "\n",
    "\n",
    "# This is similar to \"test_inputs_with_substrings\" above, but we have the AIConfig *outputs*\n",
    "# in the test cases, rather than the inputs. The library will evaluate these strings directly\n",
    "# because there is no need to run the AIConfig to generate the outputs.\n",
    "test_outputs_with_substrings = [\n",
    "    (\n",
    "        \"Begin at Chelsea Market for diverse food options. Continue to Queens for immersive food tours. Conclude at Smorgasburg for unique outdoor food market experience\",\n",
    "        \"Magnolia Bakery\"\n",
    "    ),\n",
    "    (\n",
    "        \"1. Empire State Building: Observation deck visit, explore exhibits and historical displays. 2. Rockefeller Center: Visit \\\"Top of the Rock\\\", ice-skating, NBC Studio tour, shopping and dining. 3. Chrysler Building: Admire exterior and iconic spire, photo opportunities.\",\n",
    "        \"Empire State Building\"\n",
    "    )\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "test_suite_outputs_only = []\n",
    "for test_output, substring in test_outputs_with_substrings:\n",
    "    # Add the brevity metric\n",
    "    test_fn1 = brevity\n",
    "    test_suite_outputs_only.append((test_output, test_fn1))\n",
    "    # Add substring check function\n",
    "    test_fn2 = substring_match(substring, case_sensitive=False)\n",
    "    test_suite_outputs_only.append(\n",
    "        (test_output, test_fn2)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If you like, you can inspect the test suite before passing it to the evaluation library.\n",
      "\n",
      "Test output:\n",
      " Begin at Chelsea Market for diverse food options. Continue to Queens for immersive food tours. Conclude at Smorgasburg for unique outdoor food market experience \n",
      "Function:\n",
      " Metric(calculate=<function _calculate_brevity at 0x142b18ca0>, interpretation={\n",
      "  \"name\": \"brevity\",\n",
      "  \"description\": \"Absolute text length\",\n",
      "  \"best_value\": 1.0,\n",
      "  \"worst_value\": Infinity,\n",
      "  \"extra_metadata\": {}\n",
      "})\n",
      "\n",
      "Test output:\n",
      " Begin at Chelsea Market for diverse food options. Continue to Queens for immersive food tours. Conclude at Smorgasburg for unique outdoor food market experience \n",
      "Function:\n",
      " Metric(calculate=<function substring_match.<locals>._fn at 0x142ba5ab0>, interpretation={\n",
      "  \"name\": \"substring_match\",\n",
      "  \"description\": \"1.0 (pass) if contains given substring\",\n",
      "  \"best_value\": 1.0,\n",
      "  \"worst_value\": 0.0,\n",
      "  \"extra_metadata\": {\n",
      "    \"substring\": \"Magnolia Bakery\",\n",
      "    \"case_sensitive\": false\n",
      "  }\n",
      "})\n",
      "\n",
      "Test output:\n",
      " 1. Empire State Building: Observation deck visit, explore exhibits and historical displays. 2. Rockefeller Center: Visit \"Top of the Rock\", ice-skating, NBC Studio tour, shopping and dining. 3. Chrysler Building: Admire exterior and iconic spire, photo opportunities. \n",
      "Function:\n",
      " Metric(calculate=<function _calculate_brevity at 0x142b18ca0>, interpretation={\n",
      "  \"name\": \"brevity\",\n",
      "  \"description\": \"Absolute text length\",\n",
      "  \"best_value\": 1.0,\n",
      "  \"worst_value\": Infinity,\n",
      "  \"extra_metadata\": {}\n",
      "})\n",
      "\n",
      "Test output:\n",
      " 1. Empire State Building: Observation deck visit, explore exhibits and historical displays. 2. Rockefeller Center: Visit \"Top of the Rock\", ice-skating, NBC Studio tour, shopping and dining. 3. Chrysler Building: Admire exterior and iconic spire, photo opportunities. \n",
      "Function:\n",
      " Metric(calculate=<function substring_match.<locals>._fn at 0x142ba5b40>, interpretation={\n",
      "  \"name\": \"substring_match\",\n",
      "  \"description\": \"1.0 (pass) if contains given substring\",\n",
      "  \"best_value\": 1.0,\n",
      "  \"worst_value\": 0.0,\n",
      "  \"extra_metadata\": {\n",
      "    \"substring\": \"Empire State Building\",\n",
      "    \"case_sensitive\": false\n",
      "  }\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(\"If you like, you can inspect the test suite before passing it to the evaluation library.\")\n",
    "\n",
    "for test_output, fn in test_suite_outputs_only:\n",
    "    print(\"\\nTest output:\\n\", test_output, \"\\nFunction:\\n\", fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run the eval library\n",
      "Raw output\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>aiconfig_output</th>\n",
       "      <th>value</th>\n",
       "      <th>metric_id</th>\n",
       "      <th>metric_name</th>\n",
       "      <th>metric_description</th>\n",
       "      <th>best_possible_value</th>\n",
       "      <th>worst_possible_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Missing</td>\n",
       "      <td>Begin at Chelsea Market for diverse food options. Continue to Queens for immersive food tours. Conclude at Smorgasburg for unique outdoor food market experience</td>\n",
       "      <td>160.0</td>\n",
       "      <td>1370aa8bacbe156352bf5a0d2cbf2b8dd8d54362e3e86809c7a4ae91e52530b4</td>\n",
       "      <td>brevity</td>\n",
       "      <td>Absolute text length</td>\n",
       "      <td>1.0</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Missing</td>\n",
       "      <td>Begin at Chelsea Market for diverse food options. Continue to Queens for immersive food tours. Conclude at Smorgasburg for unique outdoor food market experience</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2b849774ca14c9e75f3492f100b190cd0ff0a5e4a5a7f21f318b1ba0ea239054</td>\n",
       "      <td>substring_match</td>\n",
       "      <td>1.0 (pass) if contains given substring</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Missing</td>\n",
       "      <td>1. Empire State Building: Observation deck visit, explore exhibits and historical displays. 2. Rockefeller Center: Visit \"Top of the Rock\", ice-skating, NBC Studio tour, shopping and dining. 3. Chrysler Building: Admire exterior and iconic spire, photo opportunities.</td>\n",
       "      <td>267.0</td>\n",
       "      <td>1370aa8bacbe156352bf5a0d2cbf2b8dd8d54362e3e86809c7a4ae91e52530b4</td>\n",
       "      <td>brevity</td>\n",
       "      <td>Absolute text length</td>\n",
       "      <td>1.0</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Missing</td>\n",
       "      <td>1. Empire State Building: Observation deck visit, explore exhibits and historical displays. 2. Rockefeller Center: Visit \"Top of the Rock\", ice-skating, NBC Studio tour, shopping and dining. 3. Chrysler Building: Admire exterior and iconic spire, photo opportunities.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>e09e60224d3b9ca180ca934cbabf904a4e63843ee5f8bf060c062504dceab519</td>\n",
       "      <td>substring_match</td>\n",
       "      <td>1.0 (pass) if contains given substring</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     input  \\\n",
       "0  Missing   \n",
       "1  Missing   \n",
       "2  Missing   \n",
       "3  Missing   \n",
       "\n",
       "                                                                                                                                                                                                                                                               aiconfig_output  \\\n",
       "0                                                                                                             Begin at Chelsea Market for diverse food options. Continue to Queens for immersive food tours. Conclude at Smorgasburg for unique outdoor food market experience   \n",
       "1                                                                                                             Begin at Chelsea Market for diverse food options. Continue to Queens for immersive food tours. Conclude at Smorgasburg for unique outdoor food market experience   \n",
       "2  1. Empire State Building: Observation deck visit, explore exhibits and historical displays. 2. Rockefeller Center: Visit \"Top of the Rock\", ice-skating, NBC Studio tour, shopping and dining. 3. Chrysler Building: Admire exterior and iconic spire, photo opportunities.   \n",
       "3  1. Empire State Building: Observation deck visit, explore exhibits and historical displays. 2. Rockefeller Center: Visit \"Top of the Rock\", ice-skating, NBC Studio tour, shopping and dining. 3. Chrysler Building: Admire exterior and iconic spire, photo opportunities.   \n",
       "\n",
       "   value                                                         metric_id  \\\n",
       "0  160.0  1370aa8bacbe156352bf5a0d2cbf2b8dd8d54362e3e86809c7a4ae91e52530b4   \n",
       "1    0.0  2b849774ca14c9e75f3492f100b190cd0ff0a5e4a5a7f21f318b1ba0ea239054   \n",
       "2  267.0  1370aa8bacbe156352bf5a0d2cbf2b8dd8d54362e3e86809c7a4ae91e52530b4   \n",
       "3    1.0  e09e60224d3b9ca180ca934cbabf904a4e63843ee5f8bf060c062504dceab519   \n",
       "\n",
       "       metric_name                      metric_description  \\\n",
       "0          brevity                    Absolute text length   \n",
       "1  substring_match  1.0 (pass) if contains given substring   \n",
       "2          brevity                    Absolute text length   \n",
       "3  substring_match  1.0 (pass) if contains given substring   \n",
       "\n",
       "   best_possible_value  worst_possible_value  \n",
       "0                  1.0                   inf  \n",
       "1                  1.0                   0.0  \n",
       "2                  1.0                   inf  \n",
       "3                  1.0                   0.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Run the eval library\")\n",
    "df_result = await run_test_suite_outputs_only(\n",
    "    test_suite=test_suite_outputs_only,\n",
    ")\n",
    "print(\"Raw output\")\n",
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unstack for nicer manual review\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>metric_name</th>\n",
       "      <th>brevity</th>\n",
       "      <th>substring_match</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aiconfig_output</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1. Empire State Building: Observation deck visit, explore exhibits and historical displays. 2. Rockefeller Center: Visit \"Top of the Rock\", ice-skating, NBC Studio tour, shopping and dining. 3. Chrysler Building: Admire exterior and iconic spire, photo opportunities.</th>\n",
       "      <td>267.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Begin at Chelsea Market for diverse food options. Continue to Queens for immersive food tours. Conclude at Smorgasburg for unique outdoor food market experience</th>\n",
       "      <td>160.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "metric_name                                                                                                                                                                                                                                                                  brevity  \\\n",
       "aiconfig_output                                                                                                                                                                                                                                                                        \n",
       "1. Empire State Building: Observation deck visit, explore exhibits and historical displays. 2. Rockefeller Center: Visit \"Top of the Rock\", ice-skating, NBC Studio tour, shopping and dining. 3. Chrysler Building: Admire exterior and iconic spire, photo opportunities.    267.0   \n",
       "Begin at Chelsea Market for diverse food options. Continue to Queens for immersive food tours. Conclude at Smorgasburg for unique outdoor food market experience                                                                                                               160.0   \n",
       "\n",
       "metric_name                                                                                                                                                                                                                                                                  substring_match  \n",
       "aiconfig_output                                                                                                                                                                                                                                                                               \n",
       "1. Empire State Building: Observation deck visit, explore exhibits and historical displays. 2. Rockefeller Center: Visit \"Top of the Rock\", ice-skating, NBC Studio tour, shopping and dining. 3. Chrysler Building: Admire exterior and iconic spire, photo opportunities.              1.0  \n",
       "Begin at Chelsea Market for diverse food options. Continue to Queens for immersive food tours. Conclude at Smorgasburg for unique outdoor food market experience                                                                                                                         0.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Unstack for nicer manual review\")\n",
    "df_result.set_index([ \"aiconfig_output\", \"metric_name\"])\\\n",
    "        .value.unstack(\"metric_name\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiconfig",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
